{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a6efbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'env': {'start': 1, 'step_size': 0.1, 'shape': {'x': 30, 'y': 30}, 'horizon': 80, 'node_weight': 'constant', 'disc_size': 'small', 'n_players': 3, 'Cx_lengthscale': 2, 'Cx_noise': 0.001, 'Fx_lengthscale': 1, 'Fx_noise': 0.001, 'Cx_beta': 1.5, 'Fx_beta': 1.5, 'generate': False, 'env_file_name': 'env_data.pkl', 'cov_module': 'Matern', 'stochasticity': 0.0, 'domains': 'single_room'}, 'alg': {'gamma': 1, 'type': 'NM', 'ent_coef': 0.0, 'epochs': 50, 'lr': 0.01}, 'common': {'a': 1, 'subgrad': 'greedy', 'grad': 'pytorch', 'algo': 'both', 'init': 'deterministic', 'batch_size': 500}, 'visu': {'wb': 'online', 'a': 1}}\n",
      "x_ticks [-0.5001, -0.4999, 0.4999, 0.5001, 1.4999, 1.5001, 2.4999, 2.5001, 3.4999, 3.5001, 4.4999, 4.5001, 5.4999, 5.5001, 6.4999, 6.5001, 7.4999, 7.5001, 8.4999, 8.5001, 9.4999, 9.5001, 10.4999, 10.5001, 11.4999, 11.5001, 12.4999, 12.5001, 13.4999, 13.5001, 14.4999, 14.5001, 15.4999, 15.5001, 16.4999, 16.5001, 17.4999, 17.5001, 18.4999, 18.5001, 19.4999, 19.5001, 20.4999, 20.5001, 21.4999, 21.5001, 22.4999, 22.5001, 23.4999, 23.5001, 24.4999, 24.5001, 25.4999, 25.5001, 26.4999, 26.5001, 27.4999, 27.5001, 28.4999, 28.5001, 29.4999, 29.5001]\n",
      "y_ticks [-0.5001, -0.4999, 0.4999, 0.5001, 1.4999, 1.5001, 2.4999, 2.5001, 3.4999, 3.5001, 4.4999, 4.5001, 5.4999, 5.5001, 6.4999, 6.5001, 7.4999, 7.5001, 8.4999, 8.5001, 9.4999, 9.5001, 10.4999, 10.5001, 11.4999, 11.5001, 12.4999, 12.5001, 13.4999, 13.5001, 14.4999, 14.5001, 15.4999, 15.5001, 16.4999, 16.5001, 17.4999, 17.5001, 18.4999, 18.5001, 19.4999, 19.5001, 20.4999, 20.5001, 21.4999, 21.5001, 22.4999, 22.5001, 23.4999, 23.5001, 24.4999, 24.5001, 25.4999, 25.5001, 26.4999, 26.5001, 27.4999, 27.5001, 28.4999, 28.5001, 29.4999, 29.5001]\n",
      "None  mean  tensor(55.6900)  max  tensor(98.)  median  tensor(56.)  min  tensor(23.)  ent  tensor(1.5757)\n",
      "None  mean  tensor(94.6580)  max  tensor(120.)  median  tensor(95.)  min  tensor(59.)  ent  tensor(1.3114)\n",
      "None  mean  tensor(81.0800)  max  tensor(99.)  median  tensor(81.)  min  tensor(67.)  ent  tensor(0.9266)\n",
      "None  mean  tensor(75.8980)  max  tensor(92.)  median  tensor(75.)  min  tensor(62.)  ent  tensor(0.7148)\n",
      "None  mean  tensor(74.4760)  max  tensor(88.)  median  tensor(74.)  min  tensor(63.)  ent  tensor(0.6435)\n",
      "None  mean  tensor(76.5920)  max  tensor(98.)  median  tensor(76.)  min  tensor(60.)  ent  tensor(0.6602)\n",
      "None  mean  tensor(83.8980)  max  tensor(109.)  median  tensor(83.)  min  tensor(68.)  ent  tensor(0.7458)\n",
      "None  mean  tensor(94.1880)  max  tensor(117.)  median  tensor(95.)  min  tensor(73.)  ent  tensor(0.8285)\n",
      "None  mean  tensor(103.6140)  max  tensor(125.)  median  tensor(104.)  min  tensor(87.)  ent  tensor(0.8463)\n",
      "None  mean  tensor(101.1460)  max  tensor(117.)  median  tensor(102.)  min  tensor(80.)  ent  tensor(0.7952)\n",
      "None  mean  tensor(95.3720)  max  tensor(114.)  median  tensor(96.)  min  tensor(74.)  ent  tensor(0.7476)\n",
      "None  mean  tensor(93.6460)  max  tensor(111.)  median  tensor(94.)  min  tensor(73.)  ent  tensor(0.7359)\n",
      "None  mean  tensor(95.4040)  max  tensor(111.)  median  tensor(96.)  min  tensor(75.)  ent  tensor(0.7563)\n",
      "None  mean  tensor(99.9160)  max  tensor(115.)  median  tensor(101.)  min  tensor(82.)  ent  tensor(0.7926)\n",
      "None  mean  tensor(102.7200)  max  tensor(113.)  median  tensor(103.)  min  tensor(87.)  ent  tensor(0.8260)\n",
      "None  mean  tensor(103.6180)  max  tensor(120.)  median  tensor(104.)  min  tensor(88.)  ent  tensor(0.8423)\n",
      "None  mean  tensor(100.3000)  max  tensor(113.)  median  tensor(101.)  min  tensor(81.)  ent  tensor(0.8395)\n",
      "None  mean  tensor(97.6000)  max  tensor(112.)  median  tensor(98.)  min  tensor(75.)  ent  tensor(0.8299)\n",
      "None  mean  tensor(96.4820)  max  tensor(111.)  median  tensor(97.)  min  tensor(74.)  ent  tensor(0.8272)\n",
      "None  mean  tensor(96.2860)  max  tensor(118.)  median  tensor(97.)  min  tensor(74.)  ent  tensor(0.8364)\n",
      "None  mean  tensor(98.6560)  max  tensor(115.)  median  tensor(99.)  min  tensor(80.)  ent  tensor(0.8588)\n",
      "None  mean  tensor(101.1560)  max  tensor(121.)  median  tensor(102.)  min  tensor(79.)  ent  tensor(0.8912)\n",
      "None  mean  tensor(107.0900)  max  tensor(125.)  median  tensor(108.)  min  tensor(81.)  ent  tensor(0.9273)\n",
      "None  mean  tensor(113.2560)  max  tensor(140.)  median  tensor(113.)  min  tensor(96.)  ent  tensor(0.9512)\n",
      "None  mean  tensor(118.4800)  max  tensor(142.)  median  tensor(118.)  min  tensor(88.)  ent  tensor(0.9515)\n",
      "None  mean  tensor(122.3980)  max  tensor(150.)  median  tensor(122.)  min  tensor(93.)  ent  tensor(0.9310)\n",
      "None  mean  tensor(127.8520)  max  tensor(157.)  median  tensor(128.)  min  tensor(96.)  ent  tensor(0.8928)\n",
      "None  mean  tensor(132.4540)  max  tensor(159.)  median  tensor(133.)  min  tensor(98.)  ent  tensor(0.8491)\n",
      "None  mean  tensor(135.3160)  max  tensor(161.)  median  tensor(136.)  min  tensor(93.)  ent  tensor(0.8205)\n",
      "None  mean  tensor(137.9780)  max  tensor(162.)  median  tensor(139.)  min  tensor(92.)  ent  tensor(0.7953)\n",
      "None  mean  tensor(139.8920)  max  tensor(161.)  median  tensor(141.)  min  tensor(101.)  ent  tensor(0.7501)\n",
      "None  mean  tensor(140.0260)  max  tensor(162.)  median  tensor(142.)  min  tensor(98.)  ent  tensor(0.7209)\n",
      "None  mean  tensor(142.0360)  max  tensor(162.)  median  tensor(144.)  min  tensor(96.)  ent  tensor(0.6995)\n",
      "None  mean  tensor(142.3960)  max  tensor(162.)  median  tensor(144.)  min  tensor(101.)  ent  tensor(0.6889)\n",
      "None  mean  tensor(143.9780)  max  tensor(162.)  median  tensor(146.)  min  tensor(99.)  ent  tensor(0.6767)\n",
      "None  mean  tensor(143.6160)  max  tensor(162.)  median  tensor(146.)  min  tensor(97.)  ent  tensor(0.6626)\n",
      "None  mean  tensor(144.4640)  max  tensor(162.)  median  tensor(147.)  min  tensor(91.)  ent  tensor(0.6552)\n",
      "None  mean  tensor(144.6460)  max  tensor(162.)  median  tensor(147.)  min  tensor(98.)  ent  tensor(0.6424)\n",
      "None  mean  tensor(145.2580)  max  tensor(162.)  median  tensor(147.)  min  tensor(102.)  ent  tensor(0.6247)\n",
      "None  mean  tensor(145.9120)  max  tensor(162.)  median  tensor(148.)  min  tensor(99.)  ent  tensor(0.6087)\n",
      "None  mean  tensor(146.0120)  max  tensor(162.)  median  tensor(149.)  min  tensor(88.)  ent  tensor(0.5945)\n",
      "None  mean  tensor(144.8740)  max  tensor(162.)  median  tensor(148.)  min  tensor(99.)  ent  tensor(0.5782)\n",
      "None  mean  tensor(145.4600)  max  tensor(162.)  median  tensor(150.)  min  tensor(97.)  ent  tensor(0.5588)\n",
      "None  mean  tensor(146.0180)  max  tensor(162.)  median  tensor(150.)  min  tensor(94.)  ent  tensor(0.5383)\n",
      "None  mean  tensor(144.6020)  max  tensor(162.)  median  tensor(150.)  min  tensor(98.)  ent  tensor(0.5289)\n",
      "None  mean  tensor(144.7660)  max  tensor(162.)  median  tensor(150.)  min  tensor(94.)  ent  tensor(0.5290)\n",
      "None  mean  tensor(142.6520)  max  tensor(162.)  median  tensor(149.)  min  tensor(96.)  ent  tensor(0.5301)\n",
      "None  mean  tensor(140.4760)  max  tensor(162.)  median  tensor(147.)  min  tensor(95.)  ent  tensor(0.5292)\n",
      "None  mean  tensor(140.7600)  max  tensor(162.)  median  tensor(146.)  min  tensor(90.)  ent  tensor(0.5290)\n",
      "None  mean  tensor(141.0080)  max  tensor(162.)  median  tensor(147.)  min  tensor(84.)  ent  tensor(0.5327)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import errno\n",
    "import os\n",
    "import random\n",
    "from importlib.metadata import requires\n",
    "from timeit import timeit\n",
    "import dill as pickle\n",
    "import numpy as np\n",
    "import scipy\n",
    "import torch\n",
    "import wandb\n",
    "import yaml\n",
    "from sympy import Matrix, MatrixSymbol, derive_by_array, symarray\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "from subrl.utils.environment import GridWorld\n",
    "from subrl.utils.network import append_state\n",
    "from subrl.utils.network import policy as agent_net\n",
    "from visualization import Visu\n",
    "\n",
    "# TODO: 1. remove dependence from matrix and could run multiple times in parallel, .sh script, run it on the server, check how to plot multiple on wb,\n",
    "# can it plot different kappa's on the same with grouping\n",
    "# apply a policy gradient algorithm, since the policy is deterministic, use policy iteration/value iteration since we know the dynamics\n",
    "#\n",
    "workspace = \"subrl\"\n",
    "\n",
    "# 1) Load the config file\n",
    "with open(workspace + \"/params/\" + \"coverage/subrl_NM\" + \".yaml\") as file:\n",
    "    params = yaml.load(file, Loader=yaml.FullLoader)\n",
    "print(params)\n",
    "\n",
    "# 2) Set the path and copy params from file\n",
    "env_load_path = workspace + \\\n",
    "    \"/environments/\" + params[\"env\"][\"node_weight\"]+ \"/env_\" + \\\n",
    "    str(1)\n",
    "\n",
    "params['env']['num'] = 1 \n",
    "\n",
    "epochs = params[\"alg\"][\"epochs\"]\n",
    "\n",
    "H = params[\"env\"][\"horizon\"]\n",
    "MAX_Ret = 2*(H+1)\n",
    "if params[\"env\"][\"disc_size\"] == \"large\":\n",
    "    MAX_Ret = 3*(H+2)\n",
    "\n",
    "# 3) Setup the environement\n",
    "env = GridWorld(\n",
    "    env_params=params[\"env\"], common_params=params[\"common\"], visu_params=params[\"visu\"], env_file_path=env_load_path)\n",
    "node_size = params[\"env\"][\"shape\"]['x']*params[\"env\"][\"shape\"]['y']\n",
    "\n",
    "if params[\"env\"][\"node_weight\"] == \"entropy\" or params[\"env\"][\"node_weight\"] == \"steiner_covering\" or params[\"env\"][\"node_weight\"] == \"GP\": \n",
    "    a_file = open(env_load_path +\".pkl\", \"rb\")\n",
    "    data = pickle.load(a_file)\n",
    "    a_file.close()\n",
    "\n",
    "if params[\"env\"][\"node_weight\"] == \"entropy\":\n",
    "    env.cov = data\n",
    "if params[\"env\"][\"node_weight\"] == \"steiner_covering\":\n",
    "    env.items_loc = data\n",
    "if params[\"env\"][\"node_weight\"] == \"GP\":\n",
    "    env.weight = data\n",
    "\n",
    "visu = Visu(env_params=params[\"env\"])\n",
    "\n",
    "env.get_horizon_transition_matrix()\n",
    "\n",
    "# Agent's policy\n",
    "if params[\"alg\"][\"type\"]==\"M\" or params[\"alg\"][\"type\"]==\"SRL\":\n",
    "    agent = agent_net(2, env.action_dim)\n",
    "else:\n",
    "    agent = agent_net(H-1, env.action_dim)\n",
    "optim = torch.optim.Adam(agent.parameters(), lr=params[\"alg\"][\"lr\"])\n",
    "\n",
    "for t_eps in range(epochs):\n",
    "    mat_action = []\n",
    "    mat_state = []\n",
    "    mat_return = []\n",
    "    marginal_return = []\n",
    "    mat_done = []\n",
    "    # print(t_eps)\n",
    "    env.initialize()\n",
    "    mat_state.append(env.state)\n",
    "    init_state = env.state\n",
    "    list_batch_state = []\n",
    "    for h_iter in range(H-1):\n",
    "        if params[\"alg\"][\"type\"]==\"M\" or params[\"alg\"][\"type\"]==\"SRL\":\n",
    "            batch_state = mat_state[-1].reshape(-1, 1).float()\n",
    "            # append time index to the state\n",
    "            batch_state = torch.cat(\n",
    "                [batch_state, h_iter*torch.ones_like(batch_state)], 1)\n",
    "        else:\n",
    "            batch_state = append_state(mat_state, H-1)\n",
    "        action_prob = agent(batch_state)\n",
    "        policy_dist = Categorical(action_prob)\n",
    "        actions = policy_dist.sample()\n",
    "        mat_action.append(actions)\n",
    "        env.step(h_iter, actions)\n",
    "        mat_state.append(env.state)  # s+1\n",
    "        mat_return.append(env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]))\n",
    "        if h_iter ==0:\n",
    "            marginal_return.append(mat_return[h_iter])\n",
    "        else:\n",
    "            marginal_return.append(mat_return[h_iter] - mat_return[h_iter-1])\n",
    "        list_batch_state.append(batch_state)\n",
    "\n",
    "    ###################\n",
    "    # Compute gradients\n",
    "    ###################\n",
    "\n",
    "    states_visited = torch.vstack(list_batch_state).float()\n",
    "   \n",
    "    policy_dist = Categorical(agent(states_visited))\n",
    "    log_prob = policy_dist.log_prob(torch.hstack(mat_action))\n",
    "    batch_return = torch.hstack(marginal_return)/MAX_Ret\n",
    "\n",
    "    # - 2*policy_dist.entropy().mean()\n",
    "    J_obj = -1*(torch.mean(log_prob*batch_return) + params[\"alg\"][\"ent_coef\"] *\n",
    "                policy_dist.entropy().mean()/(t_eps+1))\n",
    "    optim.zero_grad()\n",
    "    J_obj.backward()\n",
    "    optim.step()\n",
    "\n",
    "    obj = env.weighted_traj_return(mat_state).float()\n",
    "    print(visu.JPi_optimal, \" mean \", obj.mean(), \" max \",\n",
    "          obj.max(), \" median \", obj.median(), \" min \", obj.min(), \" ent \", policy_dist.entropy().mean().detach())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ada669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
