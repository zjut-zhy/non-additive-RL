{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69eb41ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import matplotlib.pyplot as plt\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ebed152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda-python-3.11\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import errno\n",
    "import os\n",
    "import random\n",
    "from importlib.metadata import requires\n",
    "from timeit import timeit\n",
    "import dill as pickle\n",
    "import numpy as np\n",
    "import scipy\n",
    "import torch\n",
    "import wandb\n",
    "import yaml\n",
    "from sympy import Matrix, MatrixSymbol, derive_by_array, symarray\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "from subrl.utils.environment import GridWorld\n",
    "from subrl.utils.network import append_state\n",
    "from subrl.utils.network import policy as agent_net\n",
    "from subrl.utils.visualization import Visu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0d1d506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'env': {'start': 1, 'step_size': 0.1, 'shape': {'x': 7, 'y': 14}, 'horizon': 40, 'node_weight': 'constant', 'disc_size': 'small', 'n_players': 3, 'Cx_lengthscale': 2, 'Cx_noise': 0.001, 'Fx_lengthscale': 1, 'Fx_noise': 0.001, 'Cx_beta': 1.5, 'Fx_beta': 1.5, 'generate': False, 'env_file_name': 'env_data.pkl', 'cov_module': 'Matern', 'stochasticity': 0.0, 'domains': 'two_room', 'num': 1}, 'alg': {'gamma': 1, 'type': 'NM', 'ent_coef': 0.0, 'epochs': 140, 'lr': 0.02}, 'common': {'a': 1, 'subgrad': 'greedy', 'grad': 'pytorch', 'algo': 'both', 'init': 'deterministic', 'batch_size': 3000}, 'visu': {'wb': 'disabled', 'a': 1}}\n",
      "x_ticks [-0.5001, -0.4999, 0.4999, 0.5001, 1.4999, 1.5001, 2.4999, 2.5001, 3.4999, 3.5001, 4.4999, 4.5001, 5.4999, 5.5001, 6.4999, 6.5001, 7.4999, 7.5001, 8.4999, 8.5001, 9.4999, 9.5001, 10.4999, 10.5001, 11.4999, 11.5001, 12.4999, 12.5001, 13.4999, 13.5001]\n",
      "y_ticks [-0.5001, -0.4999, 0.4999, 0.5001, 1.4999, 1.5001, 2.4999, 2.5001, 3.4999, 3.5001, 4.4999, 4.5001, 5.4999, 5.5001, 6.4999, 6.5001]\n"
     ]
    }
   ],
   "source": [
    "workspace = \"subrl\"\n",
    "\n",
    "params = {\n",
    "    \"env\": {\n",
    "        \"start\": 1,\n",
    "        \"step_size\": 0.1,\n",
    "        \"shape\": {\"x\": 7, \"y\": 14},\n",
    "        \"horizon\": 40,\n",
    "        \"node_weight\": \"constant\",\n",
    "        \"disc_size\": \"small\",\n",
    "        \"n_players\": 3,\n",
    "        \"Cx_lengthscale\": 2,\n",
    "        \"Cx_noise\": 0.001,\n",
    "        \"Fx_lengthscale\": 1,\n",
    "        \"Fx_noise\": 0.001,\n",
    "        \"Cx_beta\": 1.5,\n",
    "        \"Fx_beta\": 1.5,\n",
    "        \"generate\": False,\n",
    "        \"env_file_name\": 'env_data.pkl',\n",
    "        \"cov_module\": 'Matern',\n",
    "        \"stochasticity\": 0.0,\n",
    "        \"domains\": \"two_room\",\n",
    "        \"num\": 1  # 替代原来的args.env\n",
    "    },\n",
    "    \"alg\": {\n",
    "        \"gamma\": 1,\n",
    "        \"type\": \"NM\",\n",
    "        \"ent_coef\": 0.0,\n",
    "        \"epochs\": 140,\n",
    "        \"lr\": 0.02\n",
    "    },\n",
    "    \"common\": {\n",
    "        \"a\": 1,\n",
    "        \"subgrad\": \"greedy\",\n",
    "        \"grad\": \"pytorch\",\n",
    "        \"algo\": \"both\",\n",
    "        \"init\": \"deterministic\",\n",
    "        \"batch_size\": 3000\n",
    "    },\n",
    "    \"visu\": {\n",
    "        \"wb\": \"disabled\",\n",
    "        \"a\": 1\n",
    "    }\n",
    "}\n",
    "\n",
    "print(params)\n",
    "\n",
    "# 2) Set the path and copy params from file\n",
    "env_load_path = workspace + \\\n",
    "    \"/environments/\" + params[\"env\"][\"node_weight\"]+ \"/env_\" + \\\n",
    "    str(params[\"env\"][\"num\"])\n",
    "\n",
    "\n",
    "\n",
    "epochs = params[\"alg\"][\"epochs\"]\n",
    "\n",
    "H = params[\"env\"][\"horizon\"]\n",
    "MAX_Ret = 2*(H+1)\n",
    "if params[\"env\"][\"disc_size\"] == \"large\":\n",
    "    MAX_Ret = 3*(H+2)\n",
    "\n",
    "# 3) Setup the environement\n",
    "env = GridWorld(\n",
    "    env_params=params[\"env\"], common_params=params[\"common\"], visu_params=params[\"visu\"], env_file_path=env_load_path)\n",
    "node_size = params[\"env\"][\"shape\"]['x']*params[\"env\"][\"shape\"]['y']\n",
    "# TransitionMatrix = torch.zeros(node_size, node_size)\n",
    "\n",
    "if params[\"env\"][\"node_weight\"] == \"entropy\" or params[\"env\"][\"node_weight\"] == \"steiner_covering\" or params[\"env\"][\"node_weight\"] == \"GP\": \n",
    "    a_file = open(env_load_path +\".pkl\", \"rb\")\n",
    "    data = pickle.load(a_file)\n",
    "    a_file.close()\n",
    "\n",
    "if params[\"env\"][\"node_weight\"] == \"entropy\":\n",
    "    env.cov = data\n",
    "if params[\"env\"][\"node_weight\"] == \"steiner_covering\":\n",
    "    env.items_loc = data\n",
    "if params[\"env\"][\"node_weight\"] == \"GP\":\n",
    "    env.weight = data\n",
    "\n",
    "visu = Visu(env_params=params[\"env\"])\n",
    "\n",
    "env.get_horizon_transition_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46194468",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    ''' 经验回放池 '''\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = collections.deque(maxlen=capacity)  # 队列,先进先出\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):  # 将数据加入buffer\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def sample(self, batch_size):  # 从buffer中采样数据,数量为batch_size\n",
    "        transitions = random.sample(self.buffer, batch_size)\n",
    "        state, action, reward, next_state, done = zip(*transitions)\n",
    "        return np.array(state), action, reward, np.array(next_state), done\n",
    "\n",
    "    def size(self):  # 目前buffer中数据的数量\n",
    "        return len(self.buffer)\n",
    "    \n",
    "class Qnet(torch.nn.Module):\n",
    "    ''' 只有一层隐藏层的Q网络 '''\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim):\n",
    "        super(Qnet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, action_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))  # 隐藏层使用ReLU激活函数\n",
    "        return self.fc2(x)\n",
    "\n",
    "class DQN:\n",
    "    ''' DQN算法 '''\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim, learning_rate, gamma,\n",
    "                 epsilon, target_update, device):\n",
    "        self.action_dim = action_dim\n",
    "        self.q_net = Qnet(state_dim, hidden_dim,\n",
    "                          self.action_dim).to(device)  # Q网络\n",
    "        # 目标网络\n",
    "        self.target_q_net = Qnet(state_dim, hidden_dim,\n",
    "                                 self.action_dim).to(device)\n",
    "        # 使用Adam优化器\n",
    "        self.optimizer = torch.optim.Adam(self.q_net.parameters(),\n",
    "                                          lr=learning_rate)\n",
    "        self.gamma = gamma  # 折扣因子\n",
    "        self.epsilon = epsilon  # epsilon-贪婪策略\n",
    "        self.target_update = target_update  # 目标网络更新频率\n",
    "        self.count = 0  # 计数器,记录更新次数\n",
    "        self.device = device\n",
    "\n",
    "    def take_action(self, state):  # epsilon-贪婪策略采取动作\n",
    "        if np.random.random() < self.epsilon:\n",
    "            action = np.random.randint(self.action_dim)\n",
    "        else:\n",
    "            state = torch.tensor([state], dtype=torch.float).to(self.device)\n",
    "            action = self.q_net(state).argmax().item()\n",
    "        return action\n",
    "\n",
    "    def update(self, transition_dict):\n",
    "        states = torch.tensor(transition_dict['states'],\n",
    "                              dtype=torch.float).to(self.device)\n",
    "        actions = torch.tensor(transition_dict['actions']).view(-1, 1).to(\n",
    "            self.device)\n",
    "        rewards = torch.tensor(transition_dict['rewards'],\n",
    "                               dtype=torch.float).view(-1, 1).to(self.device)\n",
    "        next_states = torch.tensor(transition_dict['next_states'],\n",
    "                                   dtype=torch.float).to(self.device)\n",
    "        dones = torch.tensor(transition_dict['dones'],\n",
    "                             dtype=torch.float).view(-1, 1).to(self.device)\n",
    "\n",
    "        q_values = self.q_net(states).gather(1, actions)  # Q值\n",
    "        # 下个状态的最大Q值\n",
    "        max_next_q_values = self.target_q_net(next_states).max(1)[0].view(\n",
    "            -1, 1)\n",
    "        q_targets = rewards + self.gamma * max_next_q_values * (1 - dones\n",
    "                                                                )  # TD误差目标\n",
    "        dqn_loss = torch.mean(F.mse_loss(q_values, q_targets))  # 均方误差损失函数\n",
    "        self.optimizer.zero_grad()  # PyTorch中默认梯度会累积,这里需要显式将梯度置为0\n",
    "        dqn_loss.backward()  # 反向传播更新参数\n",
    "        self.optimizer.step()\n",
    "\n",
    "        if self.count % self.target_update == 0:\n",
    "            self.target_q_net.load_state_dict(\n",
    "                self.q_net.state_dict())  # 更新目标网络\n",
    "        self.count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31fcb3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-3\n",
    "num_episodes = 200\n",
    "hidden_dim = 128\n",
    "gamma = 0.98\n",
    "epsilon = 0.01\n",
    "target_update = 10\n",
    "buffer_size = 10000\n",
    "minimal_size = 500\n",
    "batch_size = 64\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\n",
    "    \"cpu\")\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "state_dim = H-1\n",
    "action_dim = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c77b1400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    replay_buffer = ReplayBuffer(buffer_size)\n",
    "    agent = DQN(state_dim, hidden_dim, action_dim, lr, gamma, epsilon,\n",
    "                target_update, device)\n",
    "    params[\"common\"][\"batch_size\"]=1      #采样的batch大小\n",
    "    return_list = []\n",
    "    for i in range(10):\n",
    "        with tqdm(total=int(num_episodes / 10), desc='Iteration %d' % i) as pbar:\n",
    "            for i_episode in range(int(num_episodes / 10)):\n",
    "                mat_state = []\n",
    "                mat_return = []\n",
    "                env.initialize()\n",
    "                mat_state.append(env.state)\n",
    "                init_state = env.state\n",
    "                for h_iter in range(H-1):\n",
    "                    batch_state = append_state(mat_state, H-1)\n",
    "\n",
    "                    actions = [agent.take_action(np.array(batch_state))]\n",
    "\n",
    "                    env.step(h_iter, actions)\n",
    "\n",
    "                    mat_state.append(env.state)  # s+1\n",
    "                    mat_return.append(env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]))\n",
    "                    if h_iter == 0:\n",
    "                        reward = mat_return[-1]\n",
    "                    else:\n",
    "                        reward = mat_return[-1]-mat_return[-2]\n",
    "\n",
    "                    if h_iter == H-2:\n",
    "                        next_state = batch_state\n",
    "                        done = 1\n",
    "                    else:\n",
    "                        next_state = append_state(mat_state, H-1)\n",
    "                        done = 0\n",
    "\n",
    "                    for j in range(params[\"common\"][\"batch_size\"]):\n",
    "                        replay_buffer.add(batch_state[j],actions[j],reward[j],next_state[j],done)\n",
    "\n",
    "                    # 当buffer数据的数量超过一定值后,才进行Q网络训练\n",
    "                    if replay_buffer.size() > minimal_size:\n",
    "                        b_s, b_a, b_r, b_ns, b_d = replay_buffer.sample(batch_size)\n",
    "                        transition_dict = {\n",
    "                            'states': b_s,\n",
    "                            'actions': b_a,\n",
    "                            'next_states': b_ns,\n",
    "                            'rewards': b_r,\n",
    "                            'dones': b_d\n",
    "                        }\n",
    "                        agent.update(transition_dict)\n",
    "\n",
    "                return_list.append(mat_return[-1].float().mean())\n",
    "\n",
    "                if (i_episode + 1) % 10 == 0:\n",
    "                    pbar.set_postfix({\n",
    "                        'episode':\n",
    "                        '%d' % (num_episodes / 10 * i + i_episode + 1),\n",
    "                        'return':\n",
    "                        '%.3f' % np.mean(return_list[-10:])\n",
    "                    })\n",
    "                pbar.update(1)\n",
    "    return agent            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94c374b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 0:   0%|          | 0/20 [00:00<?, ?it/s]C:\\Users\\ZHY\\AppData\\Local\\Temp\\ipykernel_36628\\3287680778.py:18: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  actions = [agent.take_action(np.array(batch_state))]\n",
      "Iteration 0: 100%|██████████| 20/20 [00:02<00:00,  7.71it/s, episode=20, return=21.800]\n",
      "Iteration 1: 100%|██████████| 20/20 [00:05<00:00,  3.52it/s, episode=40, return=22.000]\n",
      "Iteration 2: 100%|██████████| 20/20 [00:05<00:00,  3.56it/s, episode=60, return=26.700]\n",
      "Iteration 3: 100%|██████████| 20/20 [00:05<00:00,  3.53it/s, episode=80, return=25.000]\n",
      "Iteration 4: 100%|██████████| 20/20 [00:05<00:00,  3.59it/s, episode=100, return=26.700]\n",
      "Iteration 5: 100%|██████████| 20/20 [00:05<00:00,  3.97it/s, episode=120, return=25.300]\n",
      "Iteration 6: 100%|██████████| 20/20 [00:05<00:00,  3.81it/s, episode=140, return=28.100]\n",
      "Iteration 7: 100%|██████████| 20/20 [00:04<00:00,  4.06it/s, episode=160, return=29.700]\n",
      "Iteration 8: 100%|██████████| 20/20 [00:04<00:00,  4.01it/s, episode=180, return=30.300]\n",
      "Iteration 9: 100%|██████████| 20/20 [00:05<00:00,  3.87it/s, episode=200, return=30.600]\n",
      "Iteration 0: 100%|██████████| 20/20 [00:02<00:00,  8.37it/s, episode=20, return=15.000]\n",
      "Iteration 1: 100%|██████████| 20/20 [00:05<00:00,  3.96it/s, episode=40, return=22.300]\n",
      "Iteration 2: 100%|██████████| 20/20 [00:04<00:00,  4.13it/s, episode=60, return=25.800]\n",
      "Iteration 3: 100%|██████████| 20/20 [00:04<00:00,  4.01it/s, episode=80, return=29.100]\n",
      "Iteration 4: 100%|██████████| 20/20 [00:05<00:00,  3.50it/s, episode=100, return=28.100]\n",
      "Iteration 5: 100%|██████████| 20/20 [00:05<00:00,  3.52it/s, episode=120, return=28.100]\n",
      "Iteration 6: 100%|██████████| 20/20 [00:05<00:00,  3.43it/s, episode=140, return=31.400]\n",
      "Iteration 7: 100%|██████████| 20/20 [00:07<00:00,  2.79it/s, episode=160, return=29.100]\n",
      "Iteration 8: 100%|██████████| 20/20 [00:06<00:00,  2.86it/s, episode=180, return=31.700]\n",
      "Iteration 9: 100%|██████████| 20/20 [00:06<00:00,  3.16it/s, episode=200, return=32.000]\n",
      "Iteration 0: 100%|██████████| 20/20 [00:03<00:00,  6.09it/s, episode=20, return=21.100]\n",
      "Iteration 1: 100%|██████████| 20/20 [00:05<00:00,  3.66it/s, episode=40, return=25.100]\n",
      "Iteration 2: 100%|██████████| 20/20 [00:05<00:00,  3.50it/s, episode=60, return=27.400]\n",
      "Iteration 3: 100%|██████████| 20/20 [00:05<00:00,  3.59it/s, episode=80, return=24.100]\n",
      "Iteration 4: 100%|██████████| 20/20 [00:04<00:00,  4.03it/s, episode=100, return=28.200]\n",
      "Iteration 5: 100%|██████████| 20/20 [00:04<00:00,  4.06it/s, episode=120, return=30.000]\n",
      "Iteration 6: 100%|██████████| 20/20 [00:04<00:00,  4.03it/s, episode=140, return=34.700]\n",
      "Iteration 7: 100%|██████████| 20/20 [00:05<00:00,  3.77it/s, episode=160, return=32.300]\n",
      "Iteration 8: 100%|██████████| 20/20 [00:05<00:00,  3.93it/s, episode=180, return=31.900]\n",
      "Iteration 9: 100%|██████████| 20/20 [00:05<00:00,  3.78it/s, episode=200, return=29.500]\n",
      "Iteration 0: 100%|██████████| 20/20 [00:02<00:00,  7.90it/s, episode=20, return=15.200]\n",
      "Iteration 1: 100%|██████████| 20/20 [00:04<00:00,  4.02it/s, episode=40, return=21.100]\n",
      "Iteration 2: 100%|██████████| 20/20 [00:04<00:00,  4.10it/s, episode=60, return=29.100]\n",
      "Iteration 3: 100%|██████████| 20/20 [00:04<00:00,  4.05it/s, episode=80, return=26.500]\n",
      "Iteration 4: 100%|██████████| 20/20 [00:04<00:00,  4.02it/s, episode=100, return=29.500]\n",
      "Iteration 5: 100%|██████████| 20/20 [00:04<00:00,  4.01it/s, episode=120, return=30.200]\n",
      "Iteration 6: 100%|██████████| 20/20 [00:04<00:00,  4.06it/s, episode=140, return=27.100]\n",
      "Iteration 7: 100%|██████████| 20/20 [00:04<00:00,  4.10it/s, episode=160, return=32.900]\n",
      "Iteration 8: 100%|██████████| 20/20 [00:04<00:00,  4.08it/s, episode=180, return=26.900]\n",
      "Iteration 9: 100%|██████████| 20/20 [00:05<00:00,  3.97it/s, episode=200, return=29.200]\n",
      "Iteration 0: 100%|██████████| 20/20 [00:02<00:00,  8.62it/s, episode=20, return=19.400]\n",
      "Iteration 1: 100%|██████████| 20/20 [00:04<00:00,  4.15it/s, episode=40, return=28.300]\n",
      "Iteration 2: 100%|██████████| 20/20 [00:05<00:00,  3.91it/s, episode=60, return=26.300]\n",
      "Iteration 3: 100%|██████████| 20/20 [00:04<00:00,  4.19it/s, episode=80, return=25.400]\n",
      "Iteration 4: 100%|██████████| 20/20 [00:04<00:00,  4.28it/s, episode=100, return=24.900]\n",
      "Iteration 5: 100%|██████████| 20/20 [00:04<00:00,  4.34it/s, episode=120, return=26.100]\n",
      "Iteration 6: 100%|██████████| 20/20 [00:04<00:00,  4.28it/s, episode=140, return=27.700]\n",
      "Iteration 7: 100%|██████████| 20/20 [00:04<00:00,  4.47it/s, episode=160, return=26.100]\n",
      "Iteration 8: 100%|██████████| 20/20 [00:04<00:00,  4.49it/s, episode=180, return=24.200]\n",
      "Iteration 9: 100%|██████████| 20/20 [00:04<00:00,  4.47it/s, episode=200, return=22.200]\n",
      "Iteration 0: 100%|██████████| 20/20 [00:02<00:00,  9.22it/s, episode=20, return=24.600]\n",
      "Iteration 1: 100%|██████████| 20/20 [00:04<00:00,  4.43it/s, episode=40, return=25.800]\n",
      "Iteration 2: 100%|██████████| 20/20 [00:04<00:00,  4.63it/s, episode=60, return=27.900]\n",
      "Iteration 3: 100%|██████████| 20/20 [00:04<00:00,  4.59it/s, episode=80, return=31.600]\n",
      "Iteration 4: 100%|██████████| 20/20 [00:04<00:00,  4.49it/s, episode=100, return=26.500]\n",
      "Iteration 5: 100%|██████████| 20/20 [00:04<00:00,  4.53it/s, episode=120, return=28.800]\n",
      "Iteration 6: 100%|██████████| 20/20 [00:04<00:00,  4.48it/s, episode=140, return=31.900]\n",
      "Iteration 7: 100%|██████████| 20/20 [00:04<00:00,  4.41it/s, episode=160, return=30.800]\n",
      "Iteration 8: 100%|██████████| 20/20 [00:04<00:00,  4.38it/s, episode=180, return=27.500]\n",
      "Iteration 9: 100%|██████████| 20/20 [00:04<00:00,  4.16it/s, episode=200, return=26.500]\n",
      "Iteration 0: 100%|██████████| 20/20 [00:02<00:00,  8.84it/s, episode=20, return=21.200]\n",
      "Iteration 1: 100%|██████████| 20/20 [00:04<00:00,  4.26it/s, episode=40, return=27.100]\n",
      "Iteration 2: 100%|██████████| 20/20 [00:04<00:00,  4.31it/s, episode=60, return=28.200]\n",
      "Iteration 3: 100%|██████████| 20/20 [00:04<00:00,  4.29it/s, episode=80, return=29.300]\n",
      "Iteration 4: 100%|██████████| 20/20 [00:04<00:00,  4.32it/s, episode=100, return=28.300]\n",
      "Iteration 5: 100%|██████████| 20/20 [00:04<00:00,  4.28it/s, episode=120, return=29.200]\n",
      "Iteration 6: 100%|██████████| 20/20 [00:04<00:00,  4.29it/s, episode=140, return=29.300]\n",
      "Iteration 7: 100%|██████████| 20/20 [00:04<00:00,  4.21it/s, episode=160, return=29.100]\n",
      "Iteration 8: 100%|██████████| 20/20 [00:04<00:00,  4.17it/s, episode=180, return=26.700]\n",
      "Iteration 9: 100%|██████████| 20/20 [00:04<00:00,  4.37it/s, episode=200, return=32.300]\n",
      "Iteration 0: 100%|██████████| 20/20 [00:02<00:00,  9.16it/s, episode=20, return=17.600]\n",
      "Iteration 1: 100%|██████████| 20/20 [00:04<00:00,  4.36it/s, episode=40, return=26.100]\n",
      "Iteration 2: 100%|██████████| 20/20 [00:04<00:00,  4.37it/s, episode=60, return=25.300]\n",
      "Iteration 3: 100%|██████████| 20/20 [00:04<00:00,  4.33it/s, episode=80, return=26.900]\n",
      "Iteration 4: 100%|██████████| 20/20 [00:04<00:00,  4.36it/s, episode=100, return=24.500]\n",
      "Iteration 5: 100%|██████████| 20/20 [00:04<00:00,  4.33it/s, episode=120, return=26.600]\n",
      "Iteration 6: 100%|██████████| 20/20 [00:04<00:00,  4.41it/s, episode=140, return=22.400]\n",
      "Iteration 7: 100%|██████████| 20/20 [00:04<00:00,  4.33it/s, episode=160, return=27.200]\n",
      "Iteration 8: 100%|██████████| 20/20 [00:04<00:00,  4.21it/s, episode=180, return=27.700]\n",
      "Iteration 9: 100%|██████████| 20/20 [00:04<00:00,  4.37it/s, episode=200, return=27.000]\n",
      "Iteration 0: 100%|██████████| 20/20 [00:02<00:00,  8.99it/s, episode=20, return=25.900]\n",
      "Iteration 1: 100%|██████████| 20/20 [00:04<00:00,  4.12it/s, episode=40, return=27.100]\n",
      "Iteration 2: 100%|██████████| 20/20 [00:04<00:00,  4.32it/s, episode=60, return=31.900]\n",
      "Iteration 3: 100%|██████████| 20/20 [00:04<00:00,  4.19it/s, episode=80, return=28.600]\n",
      "Iteration 4: 100%|██████████| 20/20 [00:04<00:00,  4.16it/s, episode=100, return=33.500]\n",
      "Iteration 5: 100%|██████████| 20/20 [00:04<00:00,  4.35it/s, episode=120, return=29.800]\n",
      "Iteration 6: 100%|██████████| 20/20 [00:04<00:00,  4.21it/s, episode=140, return=30.800]\n",
      "Iteration 7: 100%|██████████| 20/20 [00:04<00:00,  4.20it/s, episode=160, return=31.200]\n",
      "Iteration 8: 100%|██████████| 20/20 [00:04<00:00,  4.23it/s, episode=180, return=31.100]\n",
      "Iteration 9: 100%|██████████| 20/20 [00:04<00:00,  4.51it/s, episode=200, return=31.400]\n",
      "Iteration 0: 100%|██████████| 20/20 [00:02<00:00,  8.46it/s, episode=20, return=15.800]\n",
      "Iteration 1: 100%|██████████| 20/20 [00:04<00:00,  4.34it/s, episode=40, return=22.500]\n",
      "Iteration 2: 100%|██████████| 20/20 [00:04<00:00,  4.18it/s, episode=60, return=22.900]\n",
      "Iteration 3: 100%|██████████| 20/20 [00:04<00:00,  4.30it/s, episode=80, return=26.400]\n",
      "Iteration 4: 100%|██████████| 20/20 [00:04<00:00,  4.33it/s, episode=100, return=27.000]\n",
      "Iteration 5: 100%|██████████| 20/20 [00:04<00:00,  4.46it/s, episode=120, return=26.000]\n",
      "Iteration 6: 100%|██████████| 20/20 [00:04<00:00,  4.14it/s, episode=140, return=24.600]\n",
      "Iteration 7: 100%|██████████| 20/20 [00:04<00:00,  4.39it/s, episode=160, return=27.100]\n",
      "Iteration 8: 100%|██████████| 20/20 [00:04<00:00,  4.33it/s, episode=180, return=27.900]\n",
      "Iteration 9: 100%|██████████| 20/20 [00:04<00:00,  4.36it/s, episode=200, return=29.800]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 8.10±0.83, max: 37.90±2.02, mean: 22.40±2.00, median: 22.90±2.21\n"
     ]
    }
   ],
   "source": [
    "min_return = []\n",
    "max_return = []\n",
    "mean_return = []\n",
    "median_return = []\n",
    "for iter in range(10):\n",
    "    agent = train()\n",
    "    params[\"common\"][\"batch_size\"]=3000\n",
    "    mat_state = []\n",
    "    mat_return = []\n",
    "    env.initialize()\n",
    "    mat_state.append(env.state)\n",
    "    init_state = env.state\n",
    "    for h_iter in range(H-1):\n",
    "        batch_state = append_state(mat_state, H-1)\n",
    "        Q_value = agent.q_net(batch_state.to(device))\n",
    "        probs = F.softmax(Q_value, dim=1)  # 使用softmax将Q值转换为概率分布\n",
    "        actions_dist = torch.distributions.Categorical(probs)\n",
    "        actions = actions_dist.sample().cpu()\n",
    "        env.step(h_iter, actions)\n",
    "        mat_state.append(env.state)  # s+1\n",
    "\n",
    "    returns = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float()\n",
    "    min_return.append(returns.min())\n",
    "    max_return.append(returns.max())\n",
    "    mean_return.append(returns.mean())\n",
    "    median_return.append(returns.median())\n",
    "mean_min_return = np.mean(min_return)\n",
    "std_min_return = np.std(min_return)\n",
    "mean_max_return = np.mean(max_return)\n",
    "std_max_return = np.std(max_return)\n",
    "mean_mean_return = np.mean(mean_return)\n",
    "std_mean_return = np.std(mean_return)\n",
    "mean_median_return = np.mean(median_return)\n",
    "std_median_return = np.std(median_return)\n",
    "print(f\"min: {mean_min_return:.2f}±{std_min_return:.2f}, max: {mean_max_return:.2f}±{std_max_return:.2f}, mean: {mean_mean_return:.2f}±{std_mean_return:.2f}, median: {mean_median_return:.2f}±{std_median_return:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa9c0dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/59/76h52s611154cw1jnz1dgz5r0000gn/T/ipykernel_86605/2279627388.py:15: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  actions = [agent.take_action(np.array(batch_state))]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([42])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[\"common\"][\"batch_size\"]=1\n",
    "mat_state = []\n",
    "mat_return = []\n",
    "env.initialize()\n",
    "mat_state.append(env.state)\n",
    "init_state = env.state\n",
    "for h_iter in range(H-1):\n",
    "    if params[\"alg\"][\"type\"]==\"M\" or params[\"alg\"][\"type\"]==\"SRL\":\n",
    "        batch_state = mat_state[-1].reshape(-1, 1).float()\n",
    "        # append time index to the state\n",
    "        batch_state = torch.cat(\n",
    "            [batch_state, h_iter*torch.ones_like(batch_state)], 1)\n",
    "    else:\n",
    "        batch_state = append_state(mat_state, H-1)\n",
    "    actions = [agent.take_action(np.array(batch_state))]\n",
    "    env.step(h_iter, actions)\n",
    "    mat_state.append(env.state)  # s+1\n",
    "env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f8ddb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 34), (1, 33), (2, 32), (3, 31), (4, 30), (5, 29), (6, 28), (7, 14), (8, 0), (9, 1), (10, 0), (11, 0), (12, 14), (13, 28), (14, 28), (15, 42), (16, 56), (17, 70), (18, 71), (19, 70), (20, 71), (21, 72), (22, 71), (23, 70), (24, 70), (25, 84), (26, 70), (27, 56), (28, 42), (29, 43), (30, 44), (31, 45), (32, 46), (33, 47), (34, 48), (35, 49), (36, 50), (37, 51), (38, 52), (39, 53)]\n"
     ]
    }
   ],
   "source": [
    "def create_path_with_timesteps(states):\n",
    "    \"\"\"\n",
    "    从轨迹数据创建带时间步的路径\n",
    "    \"\"\"\n",
    "    # 将状态转换为带时间步的格式\n",
    "    path_with_time = [(t, state.item()) for t, state in enumerate(states)]\n",
    "    return path_with_time\n",
    "path = create_path_with_timesteps(mat_state)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1e64b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_ticks [-0.5001, -0.4999, 0.4999, 0.5001, 1.4999, 1.5001, 2.4999, 2.5001, 3.4999, 3.5001, 4.4999, 4.5001, 5.4999, 5.5001, 6.4999, 6.5001, 7.4999, 7.5001, 8.4999, 8.5001, 9.4999, 9.5001, 10.4999, 10.5001, 11.4999, 11.5001, 12.4999, 12.5001, 13.4999, 13.5001]\n",
      "y_ticks [-0.5001, -0.4999, 0.4999, 0.5001, 1.4999, 1.5001, 2.4999, 2.5001, 3.4999, 3.5001, 4.4999, 4.5001, 5.4999, 5.5001, 6.4999, 6.5001]\n",
      "x [6, 5, 4, 3, 2, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "y [2, 2, 2, 2, 2, 2, 2, 1, 0, 0, 0, 0, 1, 2, 2, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import importlib\n",
    "import visualization\n",
    "importlib.reload(visualization)\n",
    "from visualization import Visu\n",
    "visu = Visu(env_params=params[\"env\"])\n",
    "visu.visu_path(path,env.Hori_ActionTransitionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7f2aa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN agent's return: 42.0, min: 42.0, max: 42.0, mean: 42.0, var: 0.0\n"
     ]
    }
   ],
   "source": [
    "params[\"common\"][\"batch_size\"]=10000\n",
    "mat_state = []\n",
    "mat_return = []\n",
    "env.initialize()\n",
    "mat_state.append(env.state)\n",
    "init_state = env.state\n",
    "for h_iter in range(H-1):\n",
    "    batch_state = append_state(mat_state, H-1)\n",
    "    actions = agent.q_net(batch_state).argmax(dim=1)\n",
    "    env.step(h_iter, actions)\n",
    "    mat_state.append(env.state)  # s+1\n",
    "min_return = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float().min()\n",
    "max_return = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float().max()\n",
    "mat_return = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float().mean()\n",
    "mean_return = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float().mean()\n",
    "var_return = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float().var()\n",
    "print(f\"DQN agent's return: {mat_return}, min: {min_return}, max: {max_return}, mean: {mean_return}, var: {var_return}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30bb2124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 7.00±0.45, max: 41.30±3.41, mean: 23.65±0.03, median: 24.00±0.00\n"
     ]
    }
   ],
   "source": [
    "min_return = []\n",
    "max_return = []\n",
    "mean_return = []\n",
    "median_return = []\n",
    "for iter in range(10):\n",
    "    params[\"common\"][\"batch_size\"]=10000\n",
    "    mat_state = []\n",
    "    mat_return = []\n",
    "    env.initialize()\n",
    "    mat_state.append(env.state)\n",
    "    init_state = env.state\n",
    "    for h_iter in range(H-1):\n",
    "        batch_state = append_state(mat_state, H-1)\n",
    "        Q_value = agent.q_net(batch_state.to(device))\n",
    "        probs = F.softmax(Q_value, dim=1)  # 使用softmax将Q值转换为概率分布\n",
    "        actions_dist = torch.distributions.Categorical(probs)\n",
    "        actions = actions_dist.sample()\n",
    "        env.step(h_iter, actions)\n",
    "        mat_state.append(env.state)  # s+1\n",
    "\n",
    "    returns = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float()\n",
    "    min_return.append(returns.min())\n",
    "    max_return.append(returns.max())\n",
    "    mean_return.append(returns.mean())\n",
    "    median_return.append(returns.median())\n",
    "mean_min_return = np.mean(min_return)\n",
    "std_min_return = np.std(min_return)\n",
    "mean_max_return = np.mean(max_return)\n",
    "std_max_return = np.std(max_return)\n",
    "mean_mean_return = np.mean(mean_return)\n",
    "std_mean_return = np.std(mean_return)\n",
    "mean_median_return = np.mean(median_return)\n",
    "std_median_return = np.std(median_return)\n",
    "print(f\"min: {mean_min_return:.2f}±{std_min_return:.2f}, max: {mean_max_return:.2f}±{std_max_return:.2f}, mean: {mean_mean_return:.2f}±{std_mean_return:.2f}, median: {mean_median_return:.2f}±{std_median_return:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d01acf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
