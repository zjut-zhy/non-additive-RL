{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb44b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import matplotlib.pyplot as plt\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "418b07bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import errno\n",
    "import os\n",
    "import random\n",
    "from importlib.metadata import requires\n",
    "from timeit import timeit\n",
    "import dill as pickle\n",
    "import numpy as np\n",
    "import scipy\n",
    "import torch\n",
    "import wandb\n",
    "import yaml\n",
    "from sympy import Matrix, MatrixSymbol, derive_by_array, symarray\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "from subrl.utils.environment import GridWorld\n",
    "from subrl.utils.network import append_state\n",
    "from subrl.utils.network import policy as agent_net\n",
    "from subrl.utils.visualization import Visu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60b20453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'env': {'start': 1, 'step_size': 0.1, 'shape': {'x': 7, 'y': 14}, 'horizon': 40, 'node_weight': 'constant', 'disc_size': 'small', 'n_players': 3, 'Cx_lengthscale': 2, 'Cx_noise': 0.001, 'Fx_lengthscale': 1, 'Fx_noise': 0.001, 'Cx_beta': 1.5, 'Fx_beta': 1.5, 'generate': False, 'env_file_name': 'env_data.pkl', 'cov_module': 'Matern', 'stochasticity': 0.0, 'domains': 'two_room', 'num': 1}, 'alg': {'gamma': 1, 'type': 'NM', 'ent_coef': 0.0, 'epochs': 140, 'lr': 0.02}, 'common': {'a': 1, 'subgrad': 'greedy', 'grad': 'pytorch', 'algo': 'both', 'init': 'deterministic', 'batch_size': 3000}, 'visu': {'wb': 'disabled', 'a': 1}}\n",
      "x_ticks [-0.5001, -0.4999, 0.4999, 0.5001, 1.4999, 1.5001, 2.4999, 2.5001, 3.4999, 3.5001, 4.4999, 4.5001, 5.4999, 5.5001, 6.4999, 6.5001, 7.4999, 7.5001, 8.4999, 8.5001, 9.4999, 9.5001, 10.4999, 10.5001, 11.4999, 11.5001, 12.4999, 12.5001, 13.4999, 13.5001]\n",
      "y_ticks [-0.5001, -0.4999, 0.4999, 0.5001, 1.4999, 1.5001, 2.4999, 2.5001, 3.4999, 3.5001, 4.4999, 4.5001, 5.4999, 5.5001, 6.4999, 6.5001]\n"
     ]
    }
   ],
   "source": [
    "workspace = \"subrl\"\n",
    "\n",
    "params = {\n",
    "    \"env\": {\n",
    "        \"start\": 1,\n",
    "        \"step_size\": 0.1,\n",
    "        \"shape\": {\"x\": 7, \"y\": 14},\n",
    "        \"horizon\": 40,\n",
    "        \"node_weight\": \"constant\",\n",
    "        \"disc_size\": \"small\",\n",
    "        \"n_players\": 3,\n",
    "        \"Cx_lengthscale\": 2,\n",
    "        \"Cx_noise\": 0.001,\n",
    "        \"Fx_lengthscale\": 1,\n",
    "        \"Fx_noise\": 0.001,\n",
    "        \"Cx_beta\": 1.5,\n",
    "        \"Fx_beta\": 1.5,\n",
    "        \"generate\": False,\n",
    "        \"env_file_name\": 'env_data.pkl',\n",
    "        \"cov_module\": 'Matern',\n",
    "        \"stochasticity\": 0.0,\n",
    "        \"domains\": \"two_room\",\n",
    "        \"num\": 1  # 替代原来的args.env\n",
    "    },\n",
    "    \"alg\": {\n",
    "        \"gamma\": 1,\n",
    "        \"type\": \"NM\",\n",
    "        \"ent_coef\": 0.0,\n",
    "        \"epochs\": 140,\n",
    "        \"lr\": 0.02\n",
    "    },\n",
    "    \"common\": {\n",
    "        \"a\": 1,\n",
    "        \"subgrad\": \"greedy\",\n",
    "        \"grad\": \"pytorch\",\n",
    "        \"algo\": \"both\",\n",
    "        \"init\": \"deterministic\",\n",
    "        \"batch_size\": 3000\n",
    "    },\n",
    "    \"visu\": {\n",
    "        \"wb\": \"disabled\",\n",
    "        \"a\": 1\n",
    "    }\n",
    "}\n",
    "\n",
    "print(params)\n",
    "\n",
    "# 2) Set the path and copy params from file\n",
    "env_load_path = workspace + \\\n",
    "    \"/environments/\" + params[\"env\"][\"node_weight\"]+ \"/env_\" + \\\n",
    "    str(params[\"env\"][\"num\"])\n",
    "\n",
    "\n",
    "\n",
    "epochs = params[\"alg\"][\"epochs\"]\n",
    "\n",
    "H = params[\"env\"][\"horizon\"]\n",
    "MAX_Ret = 2*(H+1)\n",
    "if params[\"env\"][\"disc_size\"] == \"large\":\n",
    "    MAX_Ret = 3*(H+2)\n",
    "\n",
    "# 3) Setup the environement\n",
    "env = GridWorld(\n",
    "    env_params=params[\"env\"], common_params=params[\"common\"], visu_params=params[\"visu\"], env_file_path=env_load_path)\n",
    "node_size = params[\"env\"][\"shape\"]['x']*params[\"env\"][\"shape\"]['y']\n",
    "# TransitionMatrix = torch.zeros(node_size, node_size)\n",
    "\n",
    "if params[\"env\"][\"node_weight\"] == \"entropy\" or params[\"env\"][\"node_weight\"] == \"steiner_covering\" or params[\"env\"][\"node_weight\"] == \"GP\": \n",
    "    a_file = open(env_load_path +\".pkl\", \"rb\")\n",
    "    data = pickle.load(a_file)\n",
    "    a_file.close()\n",
    "\n",
    "if params[\"env\"][\"node_weight\"] == \"entropy\":\n",
    "    env.cov = data\n",
    "if params[\"env\"][\"node_weight\"] == \"steiner_covering\":\n",
    "    env.items_loc = data\n",
    "if params[\"env\"][\"node_weight\"] == \"GP\":\n",
    "    env.weight = data\n",
    "\n",
    "visu = Visu(env_params=params[\"env\"])\n",
    "\n",
    "env.get_horizon_transition_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aebe6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNet(torch.nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim):\n",
    "        super(PolicyNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, action_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return F.softmax(self.fc2(x), dim=1)\n",
    "    \n",
    "class ValueNet(torch.nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim):\n",
    "        super(ValueNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "    \n",
    "class ActorCritic:\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim, actor_lr, critic_lr,\n",
    "                 gamma, device):\n",
    "        # 策略网络\n",
    "        self.actor = PolicyNet(state_dim, hidden_dim, action_dim).to(device)\n",
    "        self.critic = ValueNet(state_dim, hidden_dim).to(device)  # 价值网络\n",
    "        # 策略网络优化器\n",
    "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(),\n",
    "                                                lr=actor_lr)\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(),\n",
    "                                                 lr=critic_lr)  # 价值网络优化器\n",
    "        self.gamma = gamma\n",
    "        self.device = device\n",
    "\n",
    "    def take_action(self, state):\n",
    "        state = torch.tensor([state], dtype=torch.float).to(self.device)\n",
    "        probs = self.actor(state)\n",
    "        action_dist = torch.distributions.Categorical(probs)\n",
    "        action = action_dist.sample()\n",
    "        return action.item()\n",
    "\n",
    "    def update(self, transition_dict):\n",
    "        states = torch.tensor(transition_dict['states'],\n",
    "                              dtype=torch.float).to(self.device)\n",
    "        actions = torch.tensor(transition_dict['actions']).view(-1, 1).to(\n",
    "            self.device)\n",
    "        rewards = torch.tensor(transition_dict['rewards'],\n",
    "                               dtype=torch.float).view(-1, 1).to(self.device)\n",
    "        next_states = torch.tensor(transition_dict['next_states'],\n",
    "                                   dtype=torch.float).to(self.device)\n",
    "        dones = torch.tensor(transition_dict['dones'],\n",
    "                             dtype=torch.float).view(-1, 1).to(self.device)\n",
    "\n",
    "        # 时序差分目标\n",
    "        td_target = rewards + self.gamma * self.critic(next_states) * (1 -\n",
    "                                                                       dones)\n",
    "        td_delta = td_target - self.critic(states)  # 时序差分误差\n",
    "        log_probs = torch.log(self.actor(states).gather(1, actions))\n",
    "        actor_loss = torch.mean(-log_probs * td_delta.detach())\n",
    "        # 均方误差损失函数\n",
    "        critic_loss = torch.mean(\n",
    "            F.mse_loss(self.critic(states), td_target.detach()))\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        actor_loss.backward()  # 计算策略网络的梯度\n",
    "        critic_loss.backward()  # 计算价值网络的梯度\n",
    "        self.actor_optimizer.step()  # 更新策略网络的参数\n",
    "        self.critic_optimizer.step()  # 更新价值网络的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ca80547",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_lr = 1e-3\n",
    "critic_lr = 1e-2\n",
    "num_episodes = 1000\n",
    "hidden_dim = 128\n",
    "gamma = 0.98\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\n",
    "    \"cpu\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "state_dim = H-1\n",
    "action_dim = 5\n",
    "agent = ActorCritic(state_dim, hidden_dim, action_dim, actor_lr, critic_lr,\n",
    "                    gamma, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c6fad76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 0:   0%|          | 0/100 [00:00<?, ?it/s]/var/folders/59/76h52s611154cw1jnz1dgz5r0000gn/T/ipykernel_87638/1899668964.py:41: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  transition_dict['states'].append(np.array(batch_state[j]))\n",
      "/var/folders/59/76h52s611154cw1jnz1dgz5r0000gn/T/ipykernel_87638/1899668964.py:43: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  transition_dict['next_states'].append(np.array(next_state[j]))\n",
      "/var/folders/59/76h52s611154cw1jnz1dgz5r0000gn/T/ipykernel_87638/4231932269.py:43: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:257.)\n",
      "  states = torch.tensor(transition_dict['states'],\n",
      "Iteration 0: 100%|██████████| 100/100 [00:00<00:00, 163.81it/s, episode=100, return=16.000]\n",
      "Iteration 1: 100%|██████████| 100/100 [00:00<00:00, 171.90it/s, episode=200, return=16.000]\n",
      "Iteration 2: 100%|██████████| 100/100 [00:00<00:00, 159.97it/s, episode=300, return=16.000]\n",
      "Iteration 3: 100%|██████████| 100/100 [00:00<00:00, 154.66it/s, episode=400, return=16.000]\n",
      "Iteration 4: 100%|██████████| 100/100 [00:00<00:00, 173.82it/s, episode=500, return=16.000]\n",
      "Iteration 5: 100%|██████████| 100/100 [00:00<00:00, 167.09it/s, episode=600, return=16.000]\n",
      "Iteration 6: 100%|██████████| 100/100 [00:00<00:00, 168.12it/s, episode=700, return=16.000]\n",
      "Iteration 7: 100%|██████████| 100/100 [00:00<00:00, 173.29it/s, episode=800, return=16.000]\n",
      "Iteration 8: 100%|██████████| 100/100 [00:00<00:00, 169.51it/s, episode=900, return=16.000]\n",
      "Iteration 9: 100%|██████████| 100/100 [00:00<00:00, 173.06it/s, episode=1000, return=16.000]\n"
     ]
    }
   ],
   "source": [
    "params[\"common\"][\"batch_size\"]=1      #采样的batch大小\n",
    "return_list = []\n",
    "for i in range(10):\n",
    "    with tqdm(total=int(num_episodes / 10), desc='Iteration %d' % i) as pbar:\n",
    "        for i_episode in range(int(num_episodes / 10)):\n",
    "            transition_dict = {\n",
    "                'states': [],\n",
    "                'actions': [],\n",
    "                'next_states': [],\n",
    "                'rewards': [],\n",
    "                'dones': []\n",
    "            }\n",
    "            mat_state = []\n",
    "            mat_return = []\n",
    "            env.initialize()\n",
    "            mat_state.append(env.state)\n",
    "            init_state = env.state\n",
    "            for h_iter in range(H-1):\n",
    "                batch_state = append_state(mat_state, H-1)\n",
    "\n",
    "                probs = agent.actor(batch_state.to(device))\n",
    "                actions_dist = torch.distributions.Categorical(probs)\n",
    "                actions = actions_dist.sample()\n",
    "\n",
    "                env.step(h_iter, actions.cpu())\n",
    "\n",
    "                mat_state.append(env.state)  # s+1\n",
    "                mat_return.append(env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]))\n",
    "                if h_iter == 0:\n",
    "                    reward = mat_return[-1]\n",
    "                else:\n",
    "                    reward = mat_return[-1]-mat_return[-2]\n",
    "\n",
    "                if h_iter == H-2:\n",
    "                    next_state = batch_state\n",
    "                    done = 1\n",
    "                else:\n",
    "                    next_state = append_state(mat_state, H-1)\n",
    "                    done = 0\n",
    "                for j in range(params[\"common\"][\"batch_size\"]):\n",
    "                    transition_dict['states'].append(np.array(batch_state[j]))\n",
    "                    transition_dict['actions'].append(actions[j])\n",
    "                    transition_dict['next_states'].append(np.array(next_state[j]))\n",
    "                    transition_dict['rewards'].append(reward[j])\n",
    "                    transition_dict['dones'].append(done)\n",
    "            return_list.append(mat_return[-1].float().mean())\n",
    "            agent.update(transition_dict)\n",
    "            if (i_episode + 1) % 10 == 0:\n",
    "                pbar.set_postfix({\n",
    "                    'episode':\n",
    "                    '%d' % (num_episodes / 10 * i + i_episode + 1),\n",
    "                    'return':\n",
    "                    '%.3f' % np.mean(return_list[-10:])\n",
    "                })\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e41201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_path_with_timesteps(states):\n",
    "    \"\"\"\n",
    "    从轨迹数据创建带时间步的路径\n",
    "    \"\"\"\n",
    "    # 将状态转换为带时间步的格式\n",
    "    path_with_time = [(t, state.item()) for t, state in enumerate(states)]\n",
    "    return path_with_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c349ac48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 34), (1, 33), (2, 32), (3, 31), (4, 30), (5, 29), (6, 28), (7, 28), (8, 28), (9, 28), (10, 28), (11, 28), (12, 28), (13, 28), (14, 28), (15, 28), (16, 28), (17, 28), (18, 28), (19, 28), (20, 28), (21, 28), (22, 28), (23, 28), (24, 28), (25, 28), (26, 28), (27, 28), (28, 28), (29, 28), (30, 28), (31, 28), (32, 28), (33, 28), (34, 28), (35, 28), (36, 28), (37, 28), (38, 28), (39, 28)]\n",
      "tensor([16])\n",
      "x_ticks [-0.5001, -0.4999, 0.4999, 0.5001, 1.4999, 1.5001, 2.4999, 2.5001, 3.4999, 3.5001, 4.4999, 4.5001, 5.4999, 5.5001, 6.4999, 6.5001, 7.4999, 7.5001, 8.4999, 8.5001, 9.4999, 9.5001, 10.4999, 10.5001, 11.4999, 11.5001, 12.4999, 12.5001, 13.4999, 13.5001]\n",
      "y_ticks [-0.5001, -0.4999, 0.4999, 0.5001, 1.4999, 1.5001, 2.4999, 2.5001, 3.4999, 3.5001, 4.4999, 4.5001, 5.4999, 5.5001, 6.4999, 6.5001]\n",
      "x [6, 5, 4, 3, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "y [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import importlib\n",
    "import visualization\n",
    "importlib.reload(visualization)\n",
    "from visualization import Visu\n",
    "params[\"common\"][\"batch_size\"]=1\n",
    "mat_state = []\n",
    "mat_return = []\n",
    "env.initialize()\n",
    "mat_state.append(env.state)\n",
    "init_state = env.state\n",
    "for h_iter in range(H-1):\n",
    "    if params[\"alg\"][\"type\"]==\"M\" or params[\"alg\"][\"type\"]==\"SRL\":\n",
    "        batch_state = mat_state[-1].reshape(-1, 1).float()\n",
    "        # append time index to the state\n",
    "        batch_state = torch.cat(\n",
    "            [batch_state, h_iter*torch.ones_like(batch_state)], 1)\n",
    "    else:\n",
    "        batch_state = append_state(mat_state, H-1)\n",
    "    probs = agent.actor(batch_state.to(device))\n",
    "    actions_dist = torch.distributions.Categorical(probs)\n",
    "    actions = actions_dist.sample()\n",
    "    env.step(h_iter, actions.cpu())\n",
    "    mat_state.append(env.state)  # s+1\n",
    "path = create_path_with_timesteps(mat_state)\n",
    "print(path)\n",
    "print(env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]))\n",
    "visu = Visu(env_params=params[\"env\"])\n",
    "visu.visu_path(path,env.Hori_ActionTransitionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14fa1871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2C agent's return: 16.0, min: 14.0, max: 18.0, mean: 16.0, var: 0.0016001600306481123\n"
     ]
    }
   ],
   "source": [
    "params[\"common\"][\"batch_size\"]=10000\n",
    "mat_state = []\n",
    "mat_return = []\n",
    "env.initialize()\n",
    "mat_state.append(env.state)\n",
    "init_state = env.state\n",
    "for h_iter in range(H-1):\n",
    "    batch_state = append_state(mat_state, H-1)\n",
    "    probs = agent.actor(batch_state.to(device))\n",
    "    actions_dist = torch.distributions.Categorical(probs)\n",
    "    actions = actions_dist.sample()\n",
    "    env.step(h_iter, actions.cpu())\n",
    "    mat_state.append(env.state)  # s+1\n",
    "min_return = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float().min()\n",
    "max_return = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float().max()\n",
    "mat_return = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float().mean()\n",
    "mean_return = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float().mean()\n",
    "var_return = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float().var()\n",
    "print(f\"A2C agent's return: {mat_return}, min: {min_return}, max: {max_return}, mean: {mean_return}, var: {var_return}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efded66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 15.20±0.98, max: 16.60±0.92, mean: 16.00±0.00, median: 16.00±0.00\n"
     ]
    }
   ],
   "source": [
    "min_return = []\n",
    "max_return = []\n",
    "mean_return = []\n",
    "median_return = []\n",
    "for iter in range(10):\n",
    "    params[\"common\"][\"batch_size\"]=1000\n",
    "    mat_state = []\n",
    "    mat_return = []\n",
    "    env.initialize()\n",
    "    mat_state.append(env.state)\n",
    "    init_state = env.state\n",
    "    for h_iter in range(H-1):\n",
    "        batch_state = append_state(mat_state, H-1)\n",
    "        probs = agent.actor(batch_state.to(device))\n",
    "        actions_dist = torch.distributions.Categorical(probs)\n",
    "        actions = actions_dist.sample()\n",
    "        env.step(h_iter, actions)\n",
    "        mat_state.append(env.state)  # s+1\n",
    "\n",
    "    returns = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float()\n",
    "    min_return.append(returns.min())\n",
    "    max_return.append(returns.max())\n",
    "    mean_return.append(returns.mean())\n",
    "    median_return.append(returns.median())\n",
    "mean_min_return = np.mean(min_return)\n",
    "std_min_return = np.std(min_return)\n",
    "mean_max_return = np.mean(max_return)\n",
    "std_max_return = np.std(max_return)\n",
    "mean_mean_return = np.mean(mean_return)\n",
    "std_mean_return = np.std(mean_return)\n",
    "mean_median_return = np.mean(median_return)\n",
    "std_median_return = np.std(median_return)\n",
    "print(f\"min: {mean_min_return:.2f}±{std_min_return:.2f}, max: {mean_max_return:.2f}±{std_max_return:.2f}, mean: {mean_mean_return:.2f}±{std_mean_return:.2f}, median: {mean_median_return:.2f}±{std_median_return:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a96261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
