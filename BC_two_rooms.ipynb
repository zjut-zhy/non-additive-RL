{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ee0c8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import gym\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "# import rl_utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import matplotlib.pyplot as plt\n",
    "import collections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "967985b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import errno\n",
    "import os\n",
    "import random\n",
    "from importlib.metadata import requires\n",
    "from timeit import timeit\n",
    "import dill as pickle\n",
    "import numpy as np\n",
    "import scipy\n",
    "import torch\n",
    "import wandb\n",
    "import yaml\n",
    "from sympy import Matrix, MatrixSymbol, derive_by_array, symarray\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "from subrl.utils.environment import GridWorld\n",
    "from subrl.utils.network import append_state\n",
    "from subrl.utils.network import policy as agent_net\n",
    "from subrl.utils.visualization import Visu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25688d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'env': {'start': 1, 'step_size': 0.1, 'shape': {'x': 7, 'y': 14}, 'horizon': 40, 'node_weight': 'constant', 'disc_size': 'small', 'n_players': 3, 'Cx_lengthscale': 2, 'Cx_noise': 0.001, 'Fx_lengthscale': 1, 'Fx_noise': 0.001, 'Cx_beta': 1.5, 'Fx_beta': 1.5, 'generate': False, 'env_file_name': 'env_data.pkl', 'cov_module': 'Matern', 'stochasticity': 0.0, 'domains': 'two_room', 'num': 1}, 'alg': {'gamma': 1, 'type': 'NM', 'ent_coef': 0.0, 'epochs': 140, 'lr': 0.02}, 'common': {'a': 1, 'subgrad': 'greedy', 'grad': 'pytorch', 'algo': 'both', 'init': 'deterministic', 'batch_size': 3000}, 'visu': {'wb': 'disabled', 'a': 1}}\n",
      "x_ticks [-0.5001, -0.4999, 0.4999, 0.5001, 1.4999, 1.5001, 2.4999, 2.5001, 3.4999, 3.5001, 4.4999, 4.5001, 5.4999, 5.5001, 6.4999, 6.5001, 7.4999, 7.5001, 8.4999, 8.5001, 9.4999, 9.5001, 10.4999, 10.5001, 11.4999, 11.5001, 12.4999, 12.5001, 13.4999, 13.5001]\n",
      "y_ticks [-0.5001, -0.4999, 0.4999, 0.5001, 1.4999, 1.5001, 2.4999, 2.5001, 3.4999, 3.5001, 4.4999, 4.5001, 5.4999, 5.5001, 6.4999, 6.5001]\n"
     ]
    }
   ],
   "source": [
    "workspace = \"subrl\"\n",
    "\n",
    "params = {\n",
    "    \"env\": {\n",
    "        \"start\": 1,\n",
    "        \"step_size\": 0.1,\n",
    "        \"shape\": {\"x\": 7, \"y\": 14},\n",
    "        \"horizon\": 40,\n",
    "        \"node_weight\": \"constant\",\n",
    "        \"disc_size\": \"small\",\n",
    "        \"n_players\": 3,\n",
    "        \"Cx_lengthscale\": 2,\n",
    "        \"Cx_noise\": 0.001,\n",
    "        \"Fx_lengthscale\": 1,\n",
    "        \"Fx_noise\": 0.001,\n",
    "        \"Cx_beta\": 1.5,\n",
    "        \"Fx_beta\": 1.5,\n",
    "        \"generate\": False,\n",
    "        \"env_file_name\": 'env_data.pkl',\n",
    "        \"cov_module\": 'Matern',\n",
    "        \"stochasticity\": 0.0,\n",
    "        \"domains\": \"two_room\",\n",
    "        \"num\": 1  # 替代原来的args.env\n",
    "    },\n",
    "    \"alg\": {\n",
    "        \"gamma\": 1,\n",
    "        \"type\": \"NM\",\n",
    "        \"ent_coef\": 0.0,\n",
    "        \"epochs\": 140,\n",
    "        \"lr\": 0.02\n",
    "    },\n",
    "    \"common\": {\n",
    "        \"a\": 1,\n",
    "        \"subgrad\": \"greedy\",\n",
    "        \"grad\": \"pytorch\",\n",
    "        \"algo\": \"both\",\n",
    "        \"init\": \"deterministic\",\n",
    "        \"batch_size\": 3000\n",
    "    },\n",
    "    \"visu\": {\n",
    "        \"wb\": \"disabled\",\n",
    "        \"a\": 1\n",
    "    }\n",
    "}\n",
    "\n",
    "print(params)\n",
    "\n",
    "# 2) Set the path and copy params from file\n",
    "env_load_path = workspace + \\\n",
    "    \"/environments/\" + params[\"env\"][\"node_weight\"]+ \"/env_\" + \\\n",
    "    str(params[\"env\"][\"num\"])\n",
    "\n",
    "\n",
    "\n",
    "epochs = params[\"alg\"][\"epochs\"]\n",
    "\n",
    "H = params[\"env\"][\"horizon\"]\n",
    "MAX_Ret = 2*(H+1)\n",
    "if params[\"env\"][\"disc_size\"] == \"large\":\n",
    "    MAX_Ret = 3*(H+2)\n",
    "\n",
    "# 3) Setup the environement\n",
    "env = GridWorld(\n",
    "    env_params=params[\"env\"], common_params=params[\"common\"], visu_params=params[\"visu\"], env_file_path=env_load_path)\n",
    "node_size = params[\"env\"][\"shape\"]['x']*params[\"env\"][\"shape\"]['y']\n",
    "# TransitionMatrix = torch.zeros(node_size, node_size)\n",
    "\n",
    "if params[\"env\"][\"node_weight\"] == \"entropy\" or params[\"env\"][\"node_weight\"] == \"steiner_covering\" or params[\"env\"][\"node_weight\"] == \"GP\": \n",
    "    a_file = open(env_load_path +\".pkl\", \"rb\")\n",
    "    data = pickle.load(a_file)\n",
    "    a_file.close()\n",
    "\n",
    "if params[\"env\"][\"node_weight\"] == \"entropy\":\n",
    "    env.cov = data\n",
    "if params[\"env\"][\"node_weight\"] == \"steiner_covering\":\n",
    "    env.items_loc = data\n",
    "if params[\"env\"][\"node_weight\"] == \"GP\":\n",
    "    env.weight = data\n",
    "\n",
    "visu = Visu(env_params=params[\"env\"])\n",
    "\n",
    "env.get_horizon_transition_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b08c4c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_excellent_trajectories(filepath=\"go_explore_archive_spacetime_10m.pkl\", \n",
    "                                  method='top_n', \n",
    "                                  n=10, \n",
    "                                  p=0.1, \n",
    "                                  threshold=0):\n",
    "    \"\"\"\n",
    "        Load data from the Go-Explore archive and sample high-quality trajectories based on the specified method.\n",
    "\n",
    "        Args:\n",
    "            filepath (str): Path to the .pkl archive file.\n",
    "            method (str): Sampling method. Options are 'top_n', 'top_p', or 'threshold'.\n",
    "            n (int): Number of trajectories to sample for the 'top_n' method.\n",
    "            p (float): Percentage of top trajectories to sample for the 'top_p' method (e.g., 0.1 means top 10%).\n",
    "            threshold (float): Minimum reward threshold for the 'threshold' method.\n",
    "        \n",
    "        Returns:\n",
    "            list: A list of trajectory dictionaries with high rewards, sorted in descending order of reward.\n",
    "                  Returns an empty list if the file does not exist or the archive is empty.\n",
    "    \"\"\"\n",
    "    # 1. Check if the file exists and load the data\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Error: Archive file not found '{filepath}'\")\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        with open(filepath, \"rb\") as f:\n",
    "            archive = pickle.load(f)\n",
    "        if not archive:\n",
    "            print(\"警告：存檔庫為空。\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"讀取文件時出錯: {e}\")\n",
    "        return []\n",
    "\n",
    "    # 2. 提取所有軌跡數據並按獎勵排序\n",
    "    # archive.values() 返回的是包含 reward, states, actions 等信息的字典\n",
    "    all_trajectories_data = list(archive.values())\n",
    "    \n",
    "    # 按 'reward' 鍵從高到低排序\n",
    "    all_trajectories_data.sort(key=lambda x: x['reward'], reverse=True)\n",
    "\n",
    "    # 3. 根據指定方法進行採樣\n",
    "    sampled_trajectories = []\n",
    "    if method == 'top_n':\n",
    "        # 取獎勵最高的前 N 條\n",
    "        num_to_sample = min(n, len(all_trajectories_data))\n",
    "        sampled_trajectories = all_trajectories_data[:num_to_sample]\n",
    "        print(f\"方法: Top-N。從 {len(all_trajectories_data)} 條軌跡中篩選出最好的 {len(sampled_trajectories)} 條。\")\n",
    "\n",
    "    elif method == 'top_p':\n",
    "        # 取獎勵最高的前 P%\n",
    "        if not (0 < p <= 1):\n",
    "            print(\"錯誤：百分比 'p' 必須在 (0, 1] 之間。\")\n",
    "            return []\n",
    "        num_to_sample = int(len(all_trajectories_data) * p)\n",
    "        sampled_trajectories = all_trajectories_data[:num_to_sample]\n",
    "        print(f\"方法: Top-P。從 {len(all_trajectories_data)} 條軌跡中篩選出最好的前 {p*100:.1f}% ({len(sampled_trajectories)} 條)。\")\n",
    "\n",
    "    elif method == 'threshold':\n",
    "        # 取獎勵高於指定門檻的所有軌跡\n",
    "        sampled_trajectories = [data for data in all_trajectories_data if data['reward'] >= threshold]\n",
    "        print(f\"方法: Threshold。從 {len(all_trajectories_data)} 條軌跡中篩選出 {len(sampled_trajectories)} 條獎勵不低於 {threshold} 的軌跡。\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"錯誤：未知的採樣方法 '{method}'。請使用 'top_n', 'top_p', 或 'threshold'。\")\n",
    "\n",
    "    return sampled_trajectories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc70c5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "方法: Top-N。從 2312 條軌跡中篩選出最好的 11 條。\n",
      "方法: Top-N。從 2312 條軌跡中篩選出最好的 11 條。\n",
      "其中最好的一條獎勵為: 68\n",
      "最差的一條（在這20條中）獎勵為: 68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_20_trajectories = sample_excellent_trajectories(method='top_n', n=11)\n",
    "top_20_trajectories_2=sample_excellent_trajectories(\n",
    "    \"go_explore_archive_spacetime_.pkl\",method='top_n', n=11)\n",
    "top_20_trajectories= top_20_trajectories + top_20_trajectories_2\n",
    "if top_20_trajectories:\n",
    "    print(f\"其中最好的一條獎勵為: {top_20_trajectories[0]['reward']}\")\n",
    "    print(f\"最差的一條（在這20條中）獎勵為: {top_20_trajectories[-1]['reward']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "395079e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始轨迹状态数量: 40\n",
      "拓展后状态数量: 40\n",
      "拓展后第一个状态的形状: torch.Size([1, 39])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[34., 34., 33., 32., 31., 45., 44., 58., 72., 71., 70., 56., 42., 28.,\n",
       "          14.,  0.,  1.,  2., 16., 17., 31., 32., 33., 34., 35., 36., 37., 38.,\n",
       "          52., 66., 80., 81., 82., 68., 54., 40., 26., 12., 11.]]),\n",
       " tensor([[34., 34., 33., 32., 31., 45., 44., 58., 72., 71., 70., 56., 42., 28.,\n",
       "          14.,  0.,  1.,  2., 16., 17., 31., 32., 33., 34., 35., 36., 37., 38.,\n",
       "          52., 66., 80., 81., 82., 68., 54., 40., 26., 12., 11.]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def expand_trajectory_states(trajectory_states, H):\n",
    "    \"\"\"\n",
    "    将轨迹状态按照 append_state 的方式进行拓展\n",
    "    \n",
    "    Args:\n",
    "        trajectory_states: 轨迹中的状态列表\n",
    "        H: 时间范围参数\n",
    "        \n",
    "    Returns:\n",
    "        expanded_states: 拓展后的状态列表\n",
    "    \"\"\"\n",
    "    expanded_states = []\n",
    "    \n",
    "    # 模拟原始代码中的 mat_state 构建过程\n",
    "    mat_state = []\n",
    "    \n",
    "    for i, state in enumerate(trajectory_states):\n",
    "        mat_state.append(state)\n",
    "        \n",
    "        # 对于除了最后一个状态外的所有状态，都进行 append_state 拓展\n",
    "        if i < H - 1:\n",
    "            # 使用 append_state 函数进行状态拓展\n",
    "            batch_state = append_state(mat_state, H-1)\n",
    "            expanded_states.append(batch_state)\n",
    "        else:\n",
    "            expanded_states.append(expanded_states[-1])  # 最后一个状态不需要拓展，直接重复最后一个状态\n",
    "    \n",
    "    return expanded_states\n",
    "\n",
    "# 使用示例：拓展最佳轨迹的状态\n",
    "H = params[\"env\"][\"horizon\"]  # 使用环境参数中的 horizon\n",
    "trajectory_states=top_20_trajectories[11]['states']\n",
    "expanded_trajectory_states = expand_trajectory_states(trajectory_states, H)\n",
    "\n",
    "print(f\"原始轨迹状态数量: {len(trajectory_states)}\")\n",
    "print(f\"拓展后状态数量: {len(expanded_trajectory_states)}\")\n",
    "\n",
    "# 查看拓展后的第一个状态的形状\n",
    "if expanded_trajectory_states:\n",
    "    print(f\"拓展后第一个状态的形状: {expanded_trajectory_states[0].shape}\")\n",
    "expanded_trajectory_states[-2],expanded_trajectory_states[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f792d366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 39)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_s = np.array(expanded_trajectory_states[:39]).squeeze()\n",
    "expert_a = np.array(top_20_trajectories[11]['actions'])\n",
    "len(expert_s), len(expert_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53a06c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(855, 855)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_s=[]\n",
    "expert_a=[]\n",
    "for traj_i in top_20_trajectories:\n",
    "    expert_s.extend(np.array(expand_trajectory_states(traj_i['states'],H)[:-1]).squeeze())\n",
    "    expert_a.extend(np.array(traj_i['actions']))\n",
    "expert_s = np.array(expert_s)\n",
    "expert_a = np.array(expert_a)\n",
    "len(expert_s), len(expert_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f9e4c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNet(torch.nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim):\n",
    "        super(PolicyNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, action_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return F.softmax(self.fc2(x), dim=1)\n",
    "\n",
    "class BehaviorClone:\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim, lr):\n",
    "        self.policy = PolicyNet(state_dim, hidden_dim, action_dim).to(device)\n",
    "        self.optimizer = torch.optim.Adam(self.policy.parameters(), lr=lr)\n",
    "\n",
    "    def learn(self, states, actions):\n",
    "        states = torch.tensor(states, dtype=torch.float).to(device)\n",
    "        actions = torch.tensor(actions).view(-1, 1).to(device)\n",
    "        log_probs = torch.log(self.policy(states).gather(1, actions))\n",
    "        bc_loss = torch.mean(-log_probs)  # 最大似然估计\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        bc_loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def take_action(self, state):\n",
    "        state = torch.tensor([state], dtype=torch.float).to(device)\n",
    "        probs = self.policy(state)\n",
    "        action_dist = torch.distributions.Categorical(probs)\n",
    "        action = action_dist.sample()\n",
    "        return action.item()\n",
    "\n",
    "\n",
    "def test_agent(agent, env, n_episode):\n",
    "    params[\"common\"][\"batch_size\"]=n_episode\n",
    "    mat_state = []\n",
    "    mat_return = []\n",
    "    env.initialize()\n",
    "    mat_state.append(env.state)\n",
    "    init_state = env.state\n",
    "    for h_iter in range(H-1):\n",
    "        if params[\"alg\"][\"type\"]==\"M\" or params[\"alg\"][\"type\"]==\"SRL\":\n",
    "            batch_state = mat_state[-1].reshape(-1, 1).float()\n",
    "            # append time index to the state\n",
    "            batch_state = torch.cat(\n",
    "                [batch_state, h_iter*torch.ones_like(batch_state)], 1)\n",
    "        else:\n",
    "            batch_state = append_state(mat_state, H-1)\n",
    "        probs = agent.policy(batch_state.to(device))\n",
    "        actions_dist = torch.distributions.Categorical(probs)\n",
    "        actions = actions_dist.sample()\n",
    "        env.step(h_iter, actions.cpu())\n",
    "        mat_state.append(env.state)  # s+1\n",
    "\n",
    "    mat_return = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float().mean()\n",
    "    return mat_return\n",
    "    \n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "state_dim = H-1\n",
    "action_dim = 5\n",
    "hidden_dim = 128\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "def train():\n",
    "    lr = 1e-3\n",
    "    bc_agent = BehaviorClone(state_dim, hidden_dim, action_dim, lr)\n",
    "    n_iterations = 10000\n",
    "    batch_size = 64\n",
    "    test_returns = []\n",
    "\n",
    "    with tqdm(total=n_iterations, desc=\"进度条\") as pbar:\n",
    "        for i in range(n_iterations):\n",
    "            sample_indices = np.random.randint(low=0,\n",
    "                                            high=expert_s.shape[0],\n",
    "                                            size=batch_size)\n",
    "            bc_agent.learn(expert_s[sample_indices], expert_a[sample_indices])\n",
    "            current_return = test_agent(bc_agent, env, 100)\n",
    "            test_returns.append(current_return)\n",
    "            if (i + 1) % 10 == 0:\n",
    "                pbar.set_postfix({'return': '%.3f' % np.mean(test_returns[-10:])})\n",
    "            pbar.update(1)\n",
    "    return bc_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6534ce7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "进度条: 100%|██████████| 10000/10000 [10:42<00:00, 15.55it/s, return=48.847]\n",
      "进度条: 100%|██████████| 10000/10000 [10:42<00:00, 15.57it/s, return=49.266]\n",
      "进度条: 100%|██████████| 10000/10000 [10:35<00:00, 15.74it/s, return=50.022]\n",
      "进度条: 100%|██████████| 10000/10000 [11:14<00:00, 14.82it/s, return=46.099]\n",
      "进度条: 100%|██████████| 10000/10000 [11:21<00:00, 14.67it/s, return=44.078]\n",
      "进度条: 100%|██████████| 10000/10000 [11:45<00:00, 14.17it/s, return=49.967]\n",
      "进度条: 100%|██████████| 10000/10000 [11:21<00:00, 14.67it/s, return=45.598]\n",
      "进度条: 100%|██████████| 10000/10000 [11:29<00:00, 14.51it/s, return=51.529]\n",
      "进度条: 100%|██████████| 10000/10000 [11:38<00:00, 14.31it/s, return=41.900]\n",
      "进度条: 100%|██████████| 10000/10000 [11:58<00:00, 13.92it/s, return=47.912]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 19.10±3.65, max: 68.00±0.00, mean: 48.47±1.93, median: 52.20±8.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "min_return = []\n",
    "max_return = []\n",
    "mean_return = []\n",
    "median_return = []\n",
    "for iter in range(10):\n",
    "    # params[\"common\"][\"batch_size\"]=1000\n",
    "    bc_agent = train()\n",
    "    mat_state = []\n",
    "    mat_return = []\n",
    "    env.initialize()\n",
    "    mat_state.append(env.state)\n",
    "    init_state = env.state\n",
    "    for h_iter in range(H-1):\n",
    "        batch_state = append_state(mat_state, H-1)\n",
    "        probs = bc_agent.policy(batch_state.to(device))\n",
    "        actions_dist = torch.distributions.Categorical(probs)\n",
    "        actions = actions_dist.sample().cpu()\n",
    "        env.step(h_iter, actions)\n",
    "        mat_state.append(env.state)  # s+1\n",
    "\n",
    "    returns = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float()\n",
    "    min_return.append(returns.min())\n",
    "    max_return.append(returns.max())\n",
    "    mean_return.append(returns.mean())\n",
    "    median_return.append(returns.median())\n",
    "mean_min_return = np.mean(min_return)\n",
    "std_min_return = np.std(min_return)\n",
    "mean_max_return = np.mean(max_return)\n",
    "std_max_return = np.std(max_return)\n",
    "mean_mean_return = np.mean(mean_return)\n",
    "std_mean_return = np.std(mean_return)\n",
    "mean_median_return = np.mean(median_return)\n",
    "std_median_return = np.std(median_return)\n",
    "print(f\"min: {mean_min_return:.2f}±{std_min_return:.2f}, max: {mean_max_return:.2f}±{std_max_return:.2f}, mean: {mean_mean_return:.2f}±{std_mean_return:.2f}, median: {mean_median_return:.2f}±{std_median_return:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b86a83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BC agent's return: 50.099998474121094, min: 17.0, max: 68.0\n"
     ]
    }
   ],
   "source": [
    "params[\"common\"][\"batch_size\"]=10\n",
    "mat_state = []\n",
    "mat_return = []\n",
    "env.initialize()\n",
    "mat_state.append(env.state)\n",
    "init_state = env.state\n",
    "for h_iter in range(H-1):\n",
    "    if params[\"alg\"][\"type\"]==\"M\" or params[\"alg\"][\"type\"]==\"SRL\":\n",
    "        batch_state = mat_state[-1].reshape(-1, 1).float()\n",
    "        # append time index to the state\n",
    "        batch_state = torch.cat(\n",
    "            [batch_state, h_iter*torch.ones_like(batch_state)], 1)\n",
    "    else:\n",
    "        batch_state = append_state(mat_state, H-1)\n",
    "    probs = bc_agent.policy(batch_state.to(device))\n",
    "    actions_dist = torch.distributions.Categorical(probs)\n",
    "    actions = actions_dist.sample()\n",
    "    env.step(h_iter, actions.cpu())\n",
    "    mat_state.append(env.state)  # s+1\n",
    "min_return = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float().min()\n",
    "max_return = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float().max()\n",
    "mat_return = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float().mean()\n",
    "print(f\"BC agent's return: {mat_return}, min: {min_return}, max: {max_return}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "917ab574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_path_with_timesteps(states):\n",
    "    \"\"\"\n",
    "    从轨迹数据创建带时间步的路径\n",
    "    \"\"\"\n",
    "    # 将状态转换为带时间步的格式\n",
    "    path_with_time = [(t, state.item()) for t, state in enumerate(states)]\n",
    "    return path_with_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff950792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 34), (1, 35), (2, 36), (3, 37), (4, 38), (5, 52), (6, 66), (7, 80), (8, 81), (9, 82), (10, 68), (11, 54), (12, 40), (13, 26), (14, 12), (15, 11), (16, 10), (17, 24), (18, 38), (19, 37), (20, 36), (21, 35), (22, 34), (23, 33), (24, 32), (25, 31), (26, 30), (27, 16), (28, 2), (29, 1), (30, 0), (31, 0), (32, 0), (33, 14), (34, 28), (35, 42), (36, 43), (37, 44), (38, 45), (39, 46)]\n",
      "tensor([60])\n",
      "x_ticks [-0.5001, -0.4999, 0.4999, 0.5001, 1.4999, 1.5001, 2.4999, 2.5001, 3.4999, 3.5001, 4.4999, 4.5001, 5.4999, 5.5001, 6.4999, 6.5001, 7.4999, 7.5001, 8.4999, 8.5001, 9.4999, 9.5001, 10.4999, 10.5001, 11.4999, 11.5001, 12.4999, 12.5001, 13.4999, 13.5001]\n",
      "y_ticks [-0.5001, -0.4999, 0.4999, 0.5001, 1.4999, 1.5001, 2.4999, 2.5001, 3.4999, 3.5001, 4.4999, 4.5001, 5.4999, 5.5001, 6.4999, 6.5001]\n",
      "x [6, 7, 8, 9, 10, 10, 10, 10, 11, 12, 12, 12, 12, 12, 12, 11, 10, 10, 10, 9, 8, 7, 6, 5, 4, 3, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 1, 2, 3, 4]\n",
      "y [2, 2, 2, 2, 2, 3, 4, 5, 5, 5, 4, 3, 2, 1, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0, 1, 2, 3, 3, 3, 3, 3]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import importlib\n",
    "import visualization\n",
    "importlib.reload(visualization)\n",
    "from visualization import Visu\n",
    "params[\"common\"][\"batch_size\"]=1\n",
    "mat_state = []\n",
    "mat_return = []\n",
    "env.initialize()\n",
    "mat_state.append(env.state)\n",
    "init_state = env.state\n",
    "for h_iter in range(H-1):\n",
    "    if params[\"alg\"][\"type\"]==\"M\" or params[\"alg\"][\"type\"]==\"SRL\":\n",
    "        batch_state = mat_state[-1].reshape(-1, 1).float()\n",
    "        # append time index to the state\n",
    "        batch_state = torch.cat(\n",
    "            [batch_state, h_iter*torch.ones_like(batch_state)], 1)\n",
    "    else:\n",
    "        batch_state = append_state(mat_state, H-1)\n",
    "    probs = bc_agent.policy(batch_state.to(device))\n",
    "    actions_dist = torch.distributions.Categorical(probs)\n",
    "    actions = actions_dist.sample()\n",
    "    env.step(h_iter, actions.cpu())\n",
    "    mat_state.append(env.state)  # s+1\n",
    "path = create_path_with_timesteps(mat_state)\n",
    "print(path)\n",
    "print(env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]))\n",
    "visu = Visu(env_params=params[\"env\"])\n",
    "visu.visu_path(path,env.Hori_ActionTransitionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8a088b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BC agent's return: 48.47589874267578, min: 14.0, max: 68.0, mean: 48.47589874267578, var: 350.4468688964844\n"
     ]
    }
   ],
   "source": [
    "params[\"common\"][\"batch_size\"]=10000\n",
    "mat_state = []\n",
    "mat_return = []\n",
    "env.initialize()\n",
    "mat_state.append(env.state)\n",
    "init_state = env.state\n",
    "for h_iter in range(H-1):\n",
    "    batch_state = append_state(mat_state, H-1)\n",
    "    probs = bc_agent.policy(batch_state.to(device))\n",
    "    actions_dist = torch.distributions.Categorical(probs)\n",
    "    actions = actions_dist.sample()\n",
    "    env.step(h_iter, actions.cpu())\n",
    "    mat_state.append(env.state)  # s+1\n",
    "min_return = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float().min()\n",
    "max_return = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float().max()\n",
    "mat_return = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float().mean()\n",
    "mean_return = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float().mean()\n",
    "var_return = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float().var()\n",
    "print(f\"BC agent's return: {mat_return}, min: {min_return}, max: {max_return}, mean: {mean_return}, var: {var_return}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce900e88",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m mat_state = []\n\u001b[32m      8\u001b[39m mat_return = []\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43menv\u001b[49m.initialize()\n\u001b[32m     10\u001b[39m mat_state.append(env.state)\n\u001b[32m     11\u001b[39m init_state = env.state\n",
      "\u001b[31mNameError\u001b[39m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "min_return = []\n",
    "max_return = []\n",
    "mean_return = []\n",
    "median_return = []\n",
    "for iter in range(10):\n",
    "    # params[\"common\"][\"batch_size\"]=1000\n",
    "    mat_state = []\n",
    "    mat_return = []\n",
    "    env.initialize()\n",
    "    mat_state.append(env.state)\n",
    "    init_state = env.state\n",
    "    for h_iter in range(H-1):\n",
    "        batch_state = append_state(mat_state, H-1)\n",
    "        probs = bc_agent.policy(batch_state.to(device))\n",
    "        actions_dist = torch.distributions.Categorical(probs)\n",
    "        actions = actions_dist.sample()\n",
    "        env.step(h_iter, actions)\n",
    "        mat_state.append(env.state)  # s+1\n",
    "\n",
    "    returns = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float()\n",
    "    min_return.append(returns.min())\n",
    "    max_return.append(returns.max())\n",
    "    mean_return.append(returns.mean())\n",
    "    median_return.append(returns.median())\n",
    "mean_min_return = np.mean(min_return)\n",
    "std_min_return = np.std(min_return)\n",
    "mean_max_return = np.mean(max_return)\n",
    "std_max_return = np.std(max_return)\n",
    "mean_mean_return = np.mean(mean_return)\n",
    "std_mean_return = np.std(mean_return)\n",
    "mean_median_return = np.mean(median_return)\n",
    "std_median_return = np.std(median_return)\n",
    "print(f\"min: {mean_min_return:.2f}±{std_min_return:.2f}, max: {mean_max_return:.2f}±{std_max_return:.2f}, mean: {mean_mean_return:.2f}±{std_mean_return:.2f}, median: {mean_median_return:.2f}±{std_median_return:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe7c4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
