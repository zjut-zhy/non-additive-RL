{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94472d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import gym\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "# import rl_utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import matplotlib.pyplot as plt\n",
    "import collections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "760dc028",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import errno\n",
    "import os\n",
    "import random\n",
    "from importlib.metadata import requires\n",
    "from timeit import timeit\n",
    "import dill as pickle\n",
    "import numpy as np\n",
    "import scipy\n",
    "import torch\n",
    "import wandb\n",
    "import yaml\n",
    "from sympy import Matrix, MatrixSymbol, derive_by_array, symarray\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "from subrl.utils.environment import GridWorld\n",
    "from subrl.utils.network import append_state\n",
    "from subrl.utils.network import policy as agent_net\n",
    "from subrl.utils.visualization import Visu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d75e119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'env': {'start': 1, 'step_size': 0.1, 'shape': {'x': 7, 'y': 14}, 'horizon': 40, 'node_weight': 'constant', 'disc_size': 'small', 'n_players': 3, 'Cx_lengthscale': 2, 'Cx_noise': 0.001, 'Fx_lengthscale': 1, 'Fx_noise': 0.001, 'Cx_beta': 1.5, 'Fx_beta': 1.5, 'generate': False, 'env_file_name': 'env_data.pkl', 'cov_module': 'Matern', 'stochasticity': 0.0, 'domains': 'two_room', 'num': 1}, 'alg': {'gamma': 1, 'type': 'NM', 'ent_coef': 0.0, 'epochs': 140, 'lr': 0.02}, 'common': {'a': 1, 'subgrad': 'greedy', 'grad': 'pytorch', 'algo': 'both', 'init': 'deterministic', 'batch_size': 3000}, 'visu': {'wb': 'disabled', 'a': 1}}\n",
      "x_ticks [-0.5001, -0.4999, 0.4999, 0.5001, 1.4999, 1.5001, 2.4999, 2.5001, 3.4999, 3.5001, 4.4999, 4.5001, 5.4999, 5.5001, 6.4999, 6.5001, 7.4999, 7.5001, 8.4999, 8.5001, 9.4999, 9.5001, 10.4999, 10.5001, 11.4999, 11.5001, 12.4999, 12.5001, 13.4999, 13.5001]\n",
      "y_ticks [-0.5001, -0.4999, 0.4999, 0.5001, 1.4999, 1.5001, 2.4999, 2.5001, 3.4999, 3.5001, 4.4999, 4.5001, 5.4999, 5.5001, 6.4999, 6.5001]\n"
     ]
    }
   ],
   "source": [
    "workspace = \"subrl\"\n",
    "\n",
    "params = {\n",
    "    \"env\": {\n",
    "        \"start\": 1,\n",
    "        \"step_size\": 0.1,\n",
    "        \"shape\": {\"x\": 7, \"y\": 14},\n",
    "        \"horizon\": 40,\n",
    "        \"node_weight\": \"constant\",\n",
    "        \"disc_size\": \"small\",\n",
    "        \"n_players\": 3,\n",
    "        \"Cx_lengthscale\": 2,\n",
    "        \"Cx_noise\": 0.001,\n",
    "        \"Fx_lengthscale\": 1,\n",
    "        \"Fx_noise\": 0.001,\n",
    "        \"Cx_beta\": 1.5,\n",
    "        \"Fx_beta\": 1.5,\n",
    "        \"generate\": False,\n",
    "        \"env_file_name\": 'env_data.pkl',\n",
    "        \"cov_module\": 'Matern',\n",
    "        \"stochasticity\": 0.0,\n",
    "        \"domains\": \"two_room\",\n",
    "        \"num\": 1  # 替代原来的args.env\n",
    "    },\n",
    "    \"alg\": {\n",
    "        \"gamma\": 1,\n",
    "        \"type\": \"NM\",\n",
    "        \"ent_coef\": 0.0,\n",
    "        \"epochs\": 140,\n",
    "        \"lr\": 0.02\n",
    "    },\n",
    "    \"common\": {\n",
    "        \"a\": 1,\n",
    "        \"subgrad\": \"greedy\",\n",
    "        \"grad\": \"pytorch\",\n",
    "        \"algo\": \"both\",\n",
    "        \"init\": \"deterministic\",\n",
    "        \"batch_size\": 3000\n",
    "    },\n",
    "    \"visu\": {\n",
    "        \"wb\": \"disabled\",\n",
    "        \"a\": 1\n",
    "    }\n",
    "}\n",
    "\n",
    "print(params)\n",
    "\n",
    "# 2) Set the path and copy params from file\n",
    "env_load_path = workspace + \\\n",
    "    \"/environments/\" + params[\"env\"][\"node_weight\"]+ \"/env_\" + \\\n",
    "    str(params[\"env\"][\"num\"])\n",
    "\n",
    "\n",
    "\n",
    "epochs = params[\"alg\"][\"epochs\"]\n",
    "\n",
    "H = params[\"env\"][\"horizon\"]\n",
    "MAX_Ret = 2*(H+1)\n",
    "if params[\"env\"][\"disc_size\"] == \"large\":\n",
    "    MAX_Ret = 3*(H+2)\n",
    "\n",
    "# 3) Setup the environement\n",
    "env = GridWorld(\n",
    "    env_params=params[\"env\"], common_params=params[\"common\"], visu_params=params[\"visu\"], env_file_path=env_load_path)\n",
    "node_size = params[\"env\"][\"shape\"]['x']*params[\"env\"][\"shape\"]['y']\n",
    "# TransitionMatrix = torch.zeros(node_size, node_size)\n",
    "\n",
    "if params[\"env\"][\"node_weight\"] == \"entropy\" or params[\"env\"][\"node_weight\"] == \"steiner_covering\" or params[\"env\"][\"node_weight\"] == \"GP\": \n",
    "    a_file = open(env_load_path +\".pkl\", \"rb\")\n",
    "    data = pickle.load(a_file)\n",
    "    a_file.close()\n",
    "\n",
    "if params[\"env\"][\"node_weight\"] == \"entropy\":\n",
    "    env.cov = data\n",
    "if params[\"env\"][\"node_weight\"] == \"steiner_covering\":\n",
    "    env.items_loc = data\n",
    "if params[\"env\"][\"node_weight\"] == \"GP\":\n",
    "    env.weight = data\n",
    "\n",
    "visu = Visu(env_params=params[\"env\"])\n",
    "\n",
    "env.get_horizon_transition_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b2f94f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_advantage(gamma, lmbda, td_delta):\n",
    "    td_delta = td_delta.detach().numpy()\n",
    "    advantage_list = []\n",
    "    advantage = 0.0\n",
    "    for delta in td_delta[::-1]:\n",
    "        advantage = gamma * lmbda * advantage + delta\n",
    "        advantage_list.append(advantage)\n",
    "    advantage_list.reverse()\n",
    "    return torch.tensor(advantage_list, dtype=torch.float)\n",
    "\n",
    "class PolicyNet(torch.nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim):\n",
    "        super(PolicyNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, action_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return F.softmax(self.fc2(x), dim=1)\n",
    "\n",
    "\n",
    "class ValueNet(torch.nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim):\n",
    "        super(ValueNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "\n",
    "class PPO:\n",
    "    ''' PPO算法,采用截断方式 '''\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim, actor_lr, critic_lr,\n",
    "                 lmbda, epochs, eps, gamma, device):\n",
    "        self.actor = PolicyNet(state_dim, hidden_dim, action_dim).to(device)\n",
    "        self.critic = ValueNet(state_dim, hidden_dim).to(device)\n",
    "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(),\n",
    "                                                lr=actor_lr)\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(),\n",
    "                                                 lr=critic_lr)\n",
    "        self.gamma = gamma\n",
    "        self.lmbda = lmbda\n",
    "        self.epochs = epochs  # 一条序列的数据用来训练轮数\n",
    "        self.eps = eps  # PPO中截断范围的参数\n",
    "        self.device = device\n",
    "\n",
    "    def take_action(self, state):\n",
    "        state = torch.tensor([state], dtype=torch.float).to(self.device)\n",
    "        probs = self.actor(state)\n",
    "        action_dist = torch.distributions.Categorical(probs)\n",
    "        action = action_dist.sample()\n",
    "        return action.item()\n",
    "\n",
    "    def update(self, transition_dict):\n",
    "        states = torch.tensor(transition_dict['states'],\n",
    "                              dtype=torch.float).to(self.device)\n",
    "        actions = torch.tensor(transition_dict['actions']).view(-1, 1).to(\n",
    "            self.device)\n",
    "        rewards = torch.tensor(transition_dict['rewards'],\n",
    "                               dtype=torch.float).view(-1, 1).to(self.device)\n",
    "        next_states = torch.tensor(transition_dict['next_states'],\n",
    "                                   dtype=torch.float).to(self.device)\n",
    "        dones = torch.tensor(transition_dict['dones'],\n",
    "                             dtype=torch.float).view(-1, 1).to(self.device)\n",
    "        td_target = rewards + self.gamma * self.critic(next_states) * (1 -\n",
    "                                                                       dones)\n",
    "        td_delta = td_target - self.critic(states)\n",
    "        advantage = compute_advantage(self.gamma, self.lmbda,\n",
    "                                               td_delta.cpu()).to(self.device)\n",
    "        old_log_probs = torch.log(self.actor(states).gather(1,actions)+1e-10).detach()\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            log_probs = torch.log(self.actor(states).gather(1, actions)+1e-10)\n",
    "            ratio = torch.exp(log_probs - old_log_probs)\n",
    "            surr1 = ratio * advantage\n",
    "            surr2 = torch.clamp(ratio, 1 - self.eps,\n",
    "                                1 + self.eps) * advantage  # 截断\n",
    "            actor_loss = torch.mean(-torch.min(surr1, surr2))  # PPO损失函数\n",
    "            critic_loss = torch.mean(\n",
    "                F.mse_loss(self.critic(states), td_target.detach()))\n",
    "            self.actor_optimizer.zero_grad()\n",
    "            self.critic_optimizer.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            critic_loss.backward()\n",
    "            self.actor_optimizer.step()\n",
    "            self.critic_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5576e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_lr = 1e-3\n",
    "critic_lr = 1e-2\n",
    "num_episodes = 500\n",
    "hidden_dim = 128\n",
    "gamma = 0.98\n",
    "lmbda = 0.95\n",
    "epochs = 10\n",
    "eps = 0.2\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\n",
    "    \"cpu\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "state_dim = H-1\n",
    "action_dim = 5\n",
    "agent = PPO(state_dim, hidden_dim, action_dim, actor_lr, critic_lr, lmbda,\n",
    "            epochs, eps, gamma, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0dc8157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 0:   0%|          | 0/50 [00:00<?, ?it/s]/var/folders/59/76h52s611154cw1jnz1dgz5r0000gn/T/ipykernel_87553/1899668964.py:41: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  transition_dict['states'].append(np.array(batch_state[j]))\n",
      "/var/folders/59/76h52s611154cw1jnz1dgz5r0000gn/T/ipykernel_87553/1899668964.py:43: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  transition_dict['next_states'].append(np.array(next_state[j]))\n",
      "Iteration 0: 100%|██████████| 50/50 [00:00<00:00, 96.34it/s, episode=50, return=22.000]\n",
      "Iteration 1: 100%|██████████| 50/50 [00:00<00:00, 87.49it/s, episode=100, return=22.000]\n",
      "Iteration 2: 100%|██████████| 50/50 [00:00<00:00, 101.91it/s, episode=150, return=22.000]\n",
      "Iteration 3: 100%|██████████| 50/50 [00:00<00:00, 104.22it/s, episode=200, return=22.000]\n",
      "Iteration 4: 100%|██████████| 50/50 [00:00<00:00, 104.59it/s, episode=250, return=23.600]\n",
      "Iteration 5: 100%|██████████| 50/50 [00:00<00:00, 103.94it/s, episode=300, return=28.000]\n",
      "Iteration 6: 100%|██████████| 50/50 [00:00<00:00, 98.21it/s, episode=350, return=28.000] \n",
      "Iteration 7: 100%|██████████| 50/50 [00:00<00:00, 101.81it/s, episode=400, return=28.000]\n",
      "Iteration 8: 100%|██████████| 50/50 [00:00<00:00, 103.01it/s, episode=450, return=28.000]\n",
      "Iteration 9: 100%|██████████| 50/50 [00:00<00:00, 102.23it/s, episode=500, return=28.000]\n"
     ]
    }
   ],
   "source": [
    "params[\"common\"][\"batch_size\"]=1      #采样的batch大小\n",
    "return_list = []\n",
    "for i in range(10):\n",
    "    with tqdm(total=int(num_episodes / 10), desc='Iteration %d' % i) as pbar:\n",
    "        for i_episode in range(int(num_episodes / 10)):\n",
    "            transition_dict = {\n",
    "                'states': [],\n",
    "                'actions': [],\n",
    "                'next_states': [],\n",
    "                'rewards': [],\n",
    "                'dones': []\n",
    "            }\n",
    "            mat_state = []\n",
    "            mat_return = []\n",
    "            env.initialize()\n",
    "            mat_state.append(env.state)\n",
    "            init_state = env.state\n",
    "            for h_iter in range(H-1):\n",
    "                batch_state = append_state(mat_state, H-1)\n",
    "\n",
    "                probs = agent.actor(batch_state.to(device))\n",
    "                actions_dist = torch.distributions.Categorical(probs)\n",
    "                actions = actions_dist.sample()\n",
    "\n",
    "                env.step(h_iter, actions.cpu())\n",
    "\n",
    "                mat_state.append(env.state)  # s+1\n",
    "                mat_return.append(env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]))\n",
    "                if h_iter == 0:\n",
    "                    reward = mat_return[-1]\n",
    "                else:\n",
    "                    reward = mat_return[-1]-mat_return[-2]\n",
    "\n",
    "                if h_iter == H-2:\n",
    "                    next_state = batch_state\n",
    "                    done = 1\n",
    "                else:\n",
    "                    next_state = append_state(mat_state, H-1)\n",
    "                    done = 0\n",
    "                for j in range(params[\"common\"][\"batch_size\"]):\n",
    "                    transition_dict['states'].append(np.array(batch_state[j]))\n",
    "                    transition_dict['actions'].append(actions[j])\n",
    "                    transition_dict['next_states'].append(np.array(next_state[j]))\n",
    "                    transition_dict['rewards'].append(reward[j])\n",
    "                    transition_dict['dones'].append(done)\n",
    "            return_list.append(mat_return[-1].float().mean())\n",
    "            agent.update(transition_dict)\n",
    "            if (i_episode + 1) % 10 == 0:\n",
    "                pbar.set_postfix({\n",
    "                    'episode':\n",
    "                    '%d' % (num_episodes / 10 * i + i_episode + 1),\n",
    "                    'return':\n",
    "                    '%.3f' % np.mean(return_list[-10:])\n",
    "                })\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f17a348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_path_with_timesteps(states):\n",
    "    \"\"\"\n",
    "    从轨迹数据创建带时间步的路径\n",
    "    \"\"\"\n",
    "    # 将状态转换为带时间步的格式\n",
    "    path_with_time = [(t, state.item()) for t, state in enumerate(states)]\n",
    "    return path_with_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f7800ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 34), (1, 33), (2, 34), (3, 35), (4, 36), (5, 37), (6, 38), (7, 39), (8, 40), (9, 41), (10, 41), (11, 40), (12, 39), (13, 38), (14, 37), (15, 36), (16, 35), (17, 34), (18, 33), (19, 32), (20, 31), (21, 30), (22, 29), (23, 28), (24, 28), (25, 28), (26, 28), (27, 28), (28, 28), (29, 28), (30, 28), (31, 28), (32, 28), (33, 28), (34, 28), (35, 28), (36, 28), (37, 28), (38, 28), (39, 28)]\n",
      "tensor([28])\n",
      "x_ticks [-0.5001, -0.4999, 0.4999, 0.5001, 1.4999, 1.5001, 2.4999, 2.5001, 3.4999, 3.5001, 4.4999, 4.5001, 5.4999, 5.5001, 6.4999, 6.5001, 7.4999, 7.5001, 8.4999, 8.5001, 9.4999, 9.5001, 10.4999, 10.5001, 11.4999, 11.5001, 12.4999, 12.5001, 13.4999, 13.5001]\n",
      "y_ticks [-0.5001, -0.4999, 0.4999, 0.5001, 1.4999, 1.5001, 2.4999, 2.5001, 3.4999, 3.5001, 4.4999, 4.5001, 5.4999, 5.5001, 6.4999, 6.5001]\n",
      "x [6, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "y [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import importlib\n",
    "import visualization\n",
    "importlib.reload(visualization)\n",
    "from visualization import Visu\n",
    "params[\"common\"][\"batch_size\"]=1\n",
    "mat_state = []\n",
    "mat_return = []\n",
    "env.initialize()\n",
    "mat_state.append(env.state)\n",
    "init_state = env.state\n",
    "for h_iter in range(H-1):\n",
    "    if params[\"alg\"][\"type\"]==\"M\" or params[\"alg\"][\"type\"]==\"SRL\":\n",
    "        batch_state = mat_state[-1].reshape(-1, 1).float()\n",
    "        # append time index to the state\n",
    "        batch_state = torch.cat(\n",
    "            [batch_state, h_iter*torch.ones_like(batch_state)], 1)\n",
    "    else:\n",
    "        batch_state = append_state(mat_state, H-1)\n",
    "    probs = agent.actor(batch_state.to(device))\n",
    "    actions_dist = torch.distributions.Categorical(probs)\n",
    "    actions = actions_dist.sample()\n",
    "    env.step(h_iter, actions.cpu())\n",
    "    mat_state.append(env.state)  # s+1\n",
    "path = create_path_with_timesteps(mat_state)\n",
    "print(path)\n",
    "print(env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]))\n",
    "visu = Visu(env_params=params[\"env\"])\n",
    "visu.visu_path(path,env.Hori_ActionTransitionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b61da6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO agent's return: 28.0, min: 28.0, max: 28.0, mean: 28.0, var: 0.0\n"
     ]
    }
   ],
   "source": [
    "params[\"common\"][\"batch_size\"]=10000\n",
    "mat_state = []\n",
    "mat_return = []\n",
    "env.initialize()\n",
    "mat_state.append(env.state)\n",
    "init_state = env.state\n",
    "for h_iter in range(H-1):\n",
    "    batch_state = append_state(mat_state, H-1)\n",
    "    probs = agent.actor(batch_state.to(device))\n",
    "    actions_dist = torch.distributions.Categorical(probs)\n",
    "    actions = actions_dist.sample()\n",
    "    env.step(h_iter, actions.cpu())\n",
    "    mat_state.append(env.state)  # s+1\n",
    "min_return = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float().min()\n",
    "max_return = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float().max()\n",
    "mat_return = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float().mean()\n",
    "mean_return = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float().mean()\n",
    "var_return = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float().var()\n",
    "print(f\"PPO agent's return: {mat_return}, min: {min_return}, max: {max_return}, mean: {mean_return}, var: {var_return}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a1851fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 28.00±0.00, max: 28.00±0.00, mean: 28.00±0.00, median: 28.00±0.00\n"
     ]
    }
   ],
   "source": [
    "min_return = []\n",
    "max_return = []\n",
    "mean_return = []\n",
    "median_return = []\n",
    "for iter in range(10):\n",
    "    params[\"common\"][\"batch_size\"]=1000\n",
    "    mat_state = []\n",
    "    mat_return = []\n",
    "    env.initialize()\n",
    "    mat_state.append(env.state)\n",
    "    init_state = env.state\n",
    "    for h_iter in range(H-1):\n",
    "        batch_state = append_state(mat_state, H-1)\n",
    "        probs = agent.actor(batch_state.to(device))\n",
    "        actions_dist = torch.distributions.Categorical(probs)\n",
    "        actions = actions_dist.sample()\n",
    "        env.step(h_iter, actions)\n",
    "        mat_state.append(env.state)  # s+1\n",
    "\n",
    "    returns = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float()\n",
    "    min_return.append(returns.min())\n",
    "    max_return.append(returns.max())\n",
    "    mean_return.append(returns.mean())\n",
    "    median_return.append(returns.median())\n",
    "mean_min_return = np.mean(min_return)\n",
    "std_min_return = np.std(min_return)\n",
    "mean_max_return = np.mean(max_return)\n",
    "std_max_return = np.std(max_return)\n",
    "mean_mean_return = np.mean(mean_return)\n",
    "std_mean_return = np.std(mean_return)\n",
    "mean_median_return = np.mean(median_return)\n",
    "std_median_return = np.std(median_return)\n",
    "print(f\"min: {mean_min_return:.2f}±{std_min_return:.2f}, max: {mean_max_return:.2f}±{std_max_return:.2f}, mean: {mean_mean_return:.2f}±{std_mean_return:.2f}, median: {mean_median_return:.2f}±{std_median_return:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3661c44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
