{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94472d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import gym\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "# import rl_utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import matplotlib.pyplot as plt\n",
    "import collections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "760dc028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import errno\n",
    "import os\n",
    "import random\n",
    "from importlib.metadata import requires\n",
    "from timeit import timeit\n",
    "import dill as pickle\n",
    "import numpy as np\n",
    "import scipy\n",
    "import torch\n",
    "import wandb\n",
    "import yaml\n",
    "from sympy import Matrix, MatrixSymbol, derive_by_array, symarray\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "from subrl.utils.environment import GridWorld\n",
    "from subrl.utils.network import append_state\n",
    "from subrl.utils.network import policy as agent_net\n",
    "from subrl.utils.visualization import Visu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d75e119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'env': {'start': 1, 'step_size': 0.1, 'shape': {'x': 7, 'y': 14}, 'horizon': 40, 'node_weight': 'constant', 'disc_size': 'small', 'n_players': 3, 'Cx_lengthscale': 2, 'Cx_noise': 0.001, 'Fx_lengthscale': 1, 'Fx_noise': 0.001, 'Cx_beta': 1.5, 'Fx_beta': 1.5, 'generate': False, 'env_file_name': 'env_data.pkl', 'cov_module': 'Matern', 'stochasticity': 0.0, 'domains': 'two_room', 'num': 1}, 'alg': {'gamma': 1, 'type': 'NM', 'ent_coef': 0.0, 'epochs': 140, 'lr': 0.02}, 'common': {'a': 1, 'subgrad': 'greedy', 'grad': 'pytorch', 'algo': 'both', 'init': 'deterministic', 'batch_size': 3000}, 'visu': {'wb': 'disabled', 'a': 1}}\n",
      "x_ticks [-0.5001, -0.4999, 0.4999, 0.5001, 1.4999, 1.5001, 2.4999, 2.5001, 3.4999, 3.5001, 4.4999, 4.5001, 5.4999, 5.5001, 6.4999, 6.5001, 7.4999, 7.5001, 8.4999, 8.5001, 9.4999, 9.5001, 10.4999, 10.5001, 11.4999, 11.5001, 12.4999, 12.5001, 13.4999, 13.5001]\n",
      "y_ticks [-0.5001, -0.4999, 0.4999, 0.5001, 1.4999, 1.5001, 2.4999, 2.5001, 3.4999, 3.5001, 4.4999, 4.5001, 5.4999, 5.5001, 6.4999, 6.5001]\n"
     ]
    }
   ],
   "source": [
    "workspace = \"subrl\"\n",
    "\n",
    "params = {\n",
    "    \"env\": {\n",
    "        \"start\": 1,\n",
    "        \"step_size\": 0.1,\n",
    "        \"shape\": {\"x\": 7, \"y\": 14},\n",
    "        \"horizon\": 40,\n",
    "        \"node_weight\": \"constant\",\n",
    "        \"disc_size\": \"small\",\n",
    "        \"n_players\": 3,\n",
    "        \"Cx_lengthscale\": 2,\n",
    "        \"Cx_noise\": 0.001,\n",
    "        \"Fx_lengthscale\": 1,\n",
    "        \"Fx_noise\": 0.001,\n",
    "        \"Cx_beta\": 1.5,\n",
    "        \"Fx_beta\": 1.5,\n",
    "        \"generate\": False,\n",
    "        \"env_file_name\": 'env_data.pkl',\n",
    "        \"cov_module\": 'Matern',\n",
    "        \"stochasticity\": 0.0,\n",
    "        \"domains\": \"two_room\",\n",
    "        \"num\": 1  # 替代原来的args.env\n",
    "    },\n",
    "    \"alg\": {\n",
    "        \"gamma\": 1,\n",
    "        \"type\": \"NM\",\n",
    "        \"ent_coef\": 0.0,\n",
    "        \"epochs\": 140,\n",
    "        \"lr\": 0.02\n",
    "    },\n",
    "    \"common\": {\n",
    "        \"a\": 1,\n",
    "        \"subgrad\": \"greedy\",\n",
    "        \"grad\": \"pytorch\",\n",
    "        \"algo\": \"both\",\n",
    "        \"init\": \"deterministic\",\n",
    "        \"batch_size\": 3000\n",
    "    },\n",
    "    \"visu\": {\n",
    "        \"wb\": \"disabled\",\n",
    "        \"a\": 1\n",
    "    }\n",
    "}\n",
    "\n",
    "print(params)\n",
    "\n",
    "# 2) Set the path and copy params from file\n",
    "env_load_path = workspace + \\\n",
    "    \"/environments/\" + params[\"env\"][\"node_weight\"]+ \"/env_\" + \\\n",
    "    str(params[\"env\"][\"num\"])\n",
    "\n",
    "\n",
    "\n",
    "epochs = params[\"alg\"][\"epochs\"]\n",
    "\n",
    "H = params[\"env\"][\"horizon\"]\n",
    "MAX_Ret = 2*(H+1)\n",
    "if params[\"env\"][\"disc_size\"] == \"large\":\n",
    "    MAX_Ret = 3*(H+2)\n",
    "\n",
    "# 3) Setup the environement\n",
    "env = GridWorld(\n",
    "    env_params=params[\"env\"], common_params=params[\"common\"], visu_params=params[\"visu\"], env_file_path=env_load_path)\n",
    "node_size = params[\"env\"][\"shape\"]['x']*params[\"env\"][\"shape\"]['y']\n",
    "# TransitionMatrix = torch.zeros(node_size, node_size)\n",
    "\n",
    "if params[\"env\"][\"node_weight\"] == \"entropy\" or params[\"env\"][\"node_weight\"] == \"steiner_covering\" or params[\"env\"][\"node_weight\"] == \"GP\": \n",
    "    a_file = open(env_load_path +\".pkl\", \"rb\")\n",
    "    data = pickle.load(a_file)\n",
    "    a_file.close()\n",
    "\n",
    "if params[\"env\"][\"node_weight\"] == \"entropy\":\n",
    "    env.cov = data\n",
    "if params[\"env\"][\"node_weight\"] == \"steiner_covering\":\n",
    "    env.items_loc = data\n",
    "if params[\"env\"][\"node_weight\"] == \"GP\":\n",
    "    env.weight = data\n",
    "\n",
    "visu = Visu(env_params=params[\"env\"])\n",
    "\n",
    "env.get_horizon_transition_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b2f94f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_advantage(gamma, lmbda, td_delta):\n",
    "    td_delta = td_delta.detach().numpy()\n",
    "    advantage_list = []\n",
    "    advantage = 0.0\n",
    "    for delta in td_delta[::-1]:\n",
    "        advantage = gamma * lmbda * advantage + delta\n",
    "        advantage_list.append(advantage)\n",
    "    advantage_list.reverse()\n",
    "    return torch.tensor(advantage_list, dtype=torch.float)\n",
    "\n",
    "class PolicyNet(torch.nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim):\n",
    "        super(PolicyNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, action_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return F.softmax(self.fc2(x), dim=1)\n",
    "\n",
    "\n",
    "class ValueNet(torch.nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim):\n",
    "        super(ValueNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "\n",
    "class PPO:\n",
    "    ''' PPO算法,采用截断方式 '''\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim, actor_lr, critic_lr,\n",
    "                 lmbda, epochs, eps, gamma, device):\n",
    "        self.actor = PolicyNet(state_dim, hidden_dim, action_dim).to(device)\n",
    "        self.critic = ValueNet(state_dim, hidden_dim).to(device)\n",
    "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(),\n",
    "                                                lr=actor_lr)\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(),\n",
    "                                                 lr=critic_lr)\n",
    "        self.gamma = gamma\n",
    "        self.lmbda = lmbda\n",
    "        self.epochs = epochs  # 一条序列的数据用来训练轮数\n",
    "        self.eps = eps  # PPO中截断范围的参数\n",
    "        self.device = device\n",
    "\n",
    "    def take_action(self, state):\n",
    "        state = torch.tensor([state], dtype=torch.float).to(self.device)\n",
    "        probs = self.actor(state)\n",
    "        action_dist = torch.distributions.Categorical(probs)\n",
    "        action = action_dist.sample()\n",
    "        return action.item()\n",
    "\n",
    "    def update(self, transition_dict):\n",
    "        states = torch.tensor(transition_dict['states'],\n",
    "                              dtype=torch.float).to(self.device)\n",
    "        actions = torch.tensor(transition_dict['actions']).view(-1, 1).to(\n",
    "            self.device)\n",
    "        rewards = torch.tensor(transition_dict['rewards'],\n",
    "                               dtype=torch.float).view(-1, 1).to(self.device)\n",
    "        next_states = torch.tensor(transition_dict['next_states'],\n",
    "                                   dtype=torch.float).to(self.device)\n",
    "        dones = torch.tensor(transition_dict['dones'],\n",
    "                             dtype=torch.float).view(-1, 1).to(self.device)\n",
    "        td_target = rewards + self.gamma * self.critic(next_states) * (1 -\n",
    "                                                                       dones)\n",
    "        td_delta = td_target - self.critic(states)\n",
    "        advantage = compute_advantage(self.gamma, self.lmbda,\n",
    "                                               td_delta.cpu()).to(self.device)\n",
    "        old_log_probs = torch.log(self.actor(states).gather(1,actions)+1e-10).detach()\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            log_probs = torch.log(self.actor(states).gather(1, actions)+1e-10)\n",
    "            ratio = torch.exp(log_probs - old_log_probs)\n",
    "            surr1 = ratio * advantage\n",
    "            surr2 = torch.clamp(ratio, 1 - self.eps,\n",
    "                                1 + self.eps) * advantage  # 截断\n",
    "            actor_loss = torch.mean(-torch.min(surr1, surr2))  # PPO损失函数\n",
    "            critic_loss = torch.mean(\n",
    "                F.mse_loss(self.critic(states), td_target.detach()))\n",
    "            self.actor_optimizer.zero_grad()\n",
    "            self.critic_optimizer.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            critic_loss.backward()\n",
    "            self.actor_optimizer.step()\n",
    "            self.critic_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5576e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_lr = 1e-3\n",
    "critic_lr = 1e-2\n",
    "num_episodes = 500\n",
    "hidden_dim = 128\n",
    "gamma = 0.98\n",
    "lmbda = 0.95\n",
    "epochs = 10\n",
    "eps = 0.2\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\n",
    "    \"cpu\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "state_dim = H-1\n",
    "action_dim = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e063e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    agent = PPO(state_dim, hidden_dim, action_dim, actor_lr, critic_lr, lmbda,\n",
    "                epochs, eps, gamma, device)\n",
    "\n",
    "    params[\"common\"][\"batch_size\"]=1      #采样的batch大小\n",
    "    return_list = []\n",
    "    for i in range(10):\n",
    "        with tqdm(total=int(num_episodes / 10), desc='Iteration %d' % i) as pbar:\n",
    "            for i_episode in range(int(num_episodes / 10)):\n",
    "                transition_dict = {\n",
    "                    'states': [],\n",
    "                    'actions': [],\n",
    "                    'next_states': [],\n",
    "                    'rewards': [],\n",
    "                    'dones': []\n",
    "                }\n",
    "                mat_state = []\n",
    "                mat_return = []\n",
    "                env.initialize()\n",
    "                mat_state.append(env.state)\n",
    "                init_state = env.state\n",
    "                for h_iter in range(H-1):\n",
    "                    batch_state = append_state(mat_state, H-1)\n",
    "\n",
    "                    probs = agent.actor(batch_state.to(device))\n",
    "                    actions_dist = torch.distributions.Categorical(probs)\n",
    "                    actions = actions_dist.sample()\n",
    "\n",
    "                    env.step(h_iter, actions.cpu())\n",
    "\n",
    "                    mat_state.append(env.state)  # s+1\n",
    "                    mat_return.append(env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]))\n",
    "                    if h_iter == 0:\n",
    "                        reward = mat_return[-1]\n",
    "                    else:\n",
    "                        reward = mat_return[-1]-mat_return[-2]\n",
    "\n",
    "                    if h_iter == H-2:\n",
    "                        next_state = batch_state\n",
    "                        done = 1\n",
    "                    else:\n",
    "                        next_state = append_state(mat_state, H-1)\n",
    "                        done = 0\n",
    "                    for j in range(params[\"common\"][\"batch_size\"]):\n",
    "                        transition_dict['states'].append(np.array(batch_state[j]))\n",
    "                        transition_dict['actions'].append(actions[j])\n",
    "                        transition_dict['next_states'].append(np.array(next_state[j]))\n",
    "                        transition_dict['rewards'].append(reward[j])\n",
    "                        transition_dict['dones'].append(done)\n",
    "                return_list.append(mat_return[-1].float().mean())\n",
    "                agent.update(transition_dict)\n",
    "                if (i_episode + 1) % 10 == 0:\n",
    "                    pbar.set_postfix({\n",
    "                        'episode':\n",
    "                        '%d' % (num_episodes / 10 * i + i_episode + 1),\n",
    "                        'return':\n",
    "                        '%.3f' % np.mean(return_list[-10:])\n",
    "                    })\n",
    "                pbar.update(1)\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2885ac78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 0:   0%|          | 0/50 [00:00<?, ?it/s]C:\\Users\\ZHY\\AppData\\Local\\Temp\\ipykernel_3020\\3743101979.py:45: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  transition_dict['states'].append(np.array(batch_state[j]))\n",
      "C:\\Users\\ZHY\\AppData\\Local\\Temp\\ipykernel_3020\\3743101979.py:47: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  transition_dict['next_states'].append(np.array(next_state[j]))\n",
      "Iteration 0: 100%|██████████| 50/50 [00:09<00:00,  5.40it/s, episode=50, return=4.000]\n",
      "Iteration 1: 100%|██████████| 50/50 [00:07<00:00,  6.28it/s, episode=100, return=4.000]\n",
      "Iteration 2: 100%|██████████| 50/50 [00:07<00:00,  7.09it/s, episode=150, return=4.000]\n",
      "Iteration 3: 100%|██████████| 50/50 [00:06<00:00,  7.76it/s, episode=200, return=4.200]\n",
      "Iteration 4: 100%|██████████| 50/50 [00:05<00:00,  8.50it/s, episode=250, return=6.000]\n",
      "Iteration 5: 100%|██████████| 50/50 [00:05<00:00,  8.52it/s, episode=300, return=16.000]\n",
      "Iteration 6: 100%|██████████| 50/50 [00:05<00:00,  8.55it/s, episode=350, return=16.000]\n",
      "Iteration 7: 100%|██████████| 50/50 [00:05<00:00,  8.57it/s, episode=400, return=16.000]\n",
      "Iteration 8: 100%|██████████| 50/50 [00:05<00:00,  8.47it/s, episode=450, return=16.000]\n",
      "Iteration 9: 100%|██████████| 50/50 [00:06<00:00,  7.83it/s, episode=500, return=16.000]\n",
      "Iteration 0: 100%|██████████| 50/50 [00:06<00:00,  7.96it/s, episode=50, return=28.000]\n",
      "Iteration 1: 100%|██████████| 50/50 [00:06<00:00,  8.06it/s, episode=100, return=28.000]\n",
      "Iteration 2: 100%|██████████| 50/50 [00:06<00:00,  8.33it/s, episode=150, return=28.000]\n",
      "Iteration 3: 100%|██████████| 50/50 [00:06<00:00,  8.30it/s, episode=200, return=28.000]\n",
      "Iteration 4: 100%|██████████| 50/50 [00:05<00:00,  8.45it/s, episode=250, return=28.000]\n",
      "Iteration 5: 100%|██████████| 50/50 [00:05<00:00,  8.34it/s, episode=300, return=28.000]\n",
      "Iteration 6: 100%|██████████| 50/50 [00:06<00:00,  7.90it/s, episode=350, return=28.000]\n",
      "Iteration 7: 100%|██████████| 50/50 [00:05<00:00,  8.36it/s, episode=400, return=28.000]\n",
      "Iteration 8: 100%|██████████| 50/50 [00:06<00:00,  8.20it/s, episode=450, return=28.000]\n",
      "Iteration 9: 100%|██████████| 50/50 [00:06<00:00,  8.15it/s, episode=500, return=28.000]\n",
      "Iteration 0: 100%|██████████| 50/50 [00:06<00:00,  8.07it/s, episode=50, return=20.000]\n",
      "Iteration 1: 100%|██████████| 50/50 [00:05<00:00,  8.54it/s, episode=100, return=20.000]\n",
      "Iteration 2: 100%|██████████| 50/50 [00:05<00:00,  8.43it/s, episode=150, return=20.000]\n",
      "Iteration 3: 100%|██████████| 50/50 [00:06<00:00,  8.29it/s, episode=200, return=16.000]\n",
      "Iteration 4: 100%|██████████| 50/50 [00:05<00:00,  8.47it/s, episode=250, return=16.000]\n",
      "Iteration 5: 100%|██████████| 50/50 [00:05<00:00,  8.61it/s, episode=300, return=16.000]\n",
      "Iteration 6: 100%|██████████| 50/50 [00:05<00:00,  8.80it/s, episode=350, return=16.000]\n",
      "Iteration 7: 100%|██████████| 50/50 [00:05<00:00,  8.51it/s, episode=400, return=16.000]\n",
      "Iteration 8: 100%|██████████| 50/50 [00:05<00:00,  8.67it/s, episode=450, return=16.000]\n",
      "Iteration 9: 100%|██████████| 50/50 [00:05<00:00,  8.86it/s, episode=500, return=16.000]\n",
      "Iteration 0: 100%|██████████| 50/50 [00:05<00:00,  8.47it/s, episode=50, return=28.000]\n",
      "Iteration 1: 100%|██████████| 50/50 [00:05<00:00,  8.76it/s, episode=100, return=20.600]\n",
      "Iteration 2: 100%|██████████| 50/50 [00:05<00:00,  8.76it/s, episode=150, return=23.000]\n",
      "Iteration 3: 100%|██████████| 50/50 [00:05<00:00,  8.63it/s, episode=200, return=27.800]\n",
      "Iteration 4: 100%|██████████| 50/50 [00:05<00:00,  8.70it/s, episode=250, return=28.000]\n",
      "Iteration 5: 100%|██████████| 50/50 [00:07<00:00,  6.83it/s, episode=300, return=28.000]\n",
      "Iteration 6: 100%|██████████| 50/50 [00:06<00:00,  7.72it/s, episode=350, return=27.600]\n",
      "Iteration 7: 100%|██████████| 50/50 [00:07<00:00,  6.50it/s, episode=400, return=28.000]\n",
      "Iteration 8: 100%|██████████| 50/50 [00:09<00:00,  5.29it/s, episode=450, return=28.000]\n",
      "Iteration 9: 100%|██████████| 50/50 [00:07<00:00,  6.62it/s, episode=500, return=24.200]\n",
      "Iteration 0: 100%|██████████| 50/50 [00:09<00:00,  5.05it/s, episode=50, return=24.000]\n",
      "Iteration 1: 100%|██████████| 50/50 [00:08<00:00,  5.64it/s, episode=100, return=28.000]\n",
      "Iteration 2: 100%|██████████| 50/50 [00:06<00:00,  7.93it/s, episode=150, return=28.000]\n",
      "Iteration 3: 100%|██████████| 50/50 [00:09<00:00,  5.55it/s, episode=200, return=28.000]\n",
      "Iteration 4: 100%|██████████| 50/50 [00:07<00:00,  6.82it/s, episode=250, return=28.000]\n",
      "Iteration 5: 100%|██████████| 50/50 [00:07<00:00,  6.70it/s, episode=300, return=28.000]\n",
      "Iteration 6: 100%|██████████| 50/50 [00:06<00:00,  8.19it/s, episode=350, return=28.000]\n",
      "Iteration 7: 100%|██████████| 50/50 [00:07<00:00,  6.77it/s, episode=400, return=28.000]\n",
      "Iteration 8: 100%|██████████| 50/50 [00:08<00:00,  5.69it/s, episode=450, return=28.000]\n",
      "Iteration 9: 100%|██████████| 50/50 [00:08<00:00,  5.75it/s, episode=500, return=28.000]\n",
      "Iteration 0: 100%|██████████| 50/50 [00:08<00:00,  5.82it/s, episode=50, return=14.000]\n",
      "Iteration 1: 100%|██████████| 50/50 [00:07<00:00,  6.69it/s, episode=100, return=14.000]\n",
      "Iteration 2: 100%|██████████| 50/50 [00:06<00:00,  7.39it/s, episode=150, return=14.000]\n",
      "Iteration 3: 100%|██████████| 50/50 [00:07<00:00,  6.67it/s, episode=200, return=14.000]\n",
      "Iteration 4: 100%|██████████| 50/50 [00:06<00:00,  8.29it/s, episode=250, return=14.000]\n",
      "Iteration 5: 100%|██████████| 50/50 [00:06<00:00,  7.69it/s, episode=300, return=14.000]\n",
      "Iteration 6: 100%|██████████| 50/50 [00:06<00:00,  7.59it/s, episode=350, return=14.000]\n",
      "Iteration 7: 100%|██████████| 50/50 [00:06<00:00,  7.36it/s, episode=400, return=14.000]\n",
      "Iteration 8: 100%|██████████| 50/50 [00:06<00:00,  7.92it/s, episode=450, return=14.000]\n",
      "Iteration 9: 100%|██████████| 50/50 [00:09<00:00,  5.40it/s, episode=500, return=15.600]\n",
      "Iteration 0: 100%|██████████| 50/50 [00:06<00:00,  7.57it/s, episode=50, return=6.000]\n",
      "Iteration 1: 100%|██████████| 50/50 [00:06<00:00,  8.15it/s, episode=100, return=6.000]\n",
      "Iteration 2: 100%|██████████| 50/50 [00:06<00:00,  7.92it/s, episode=150, return=17.000]\n",
      "Iteration 3: 100%|██████████| 50/50 [00:06<00:00,  7.81it/s, episode=200, return=17.000]\n",
      "Iteration 4: 100%|██████████| 50/50 [00:06<00:00,  7.37it/s, episode=250, return=17.000]\n",
      "Iteration 5: 100%|██████████| 50/50 [00:05<00:00,  8.52it/s, episode=300, return=17.000]\n",
      "Iteration 6: 100%|██████████| 50/50 [00:06<00:00,  7.56it/s, episode=350, return=21.000]\n",
      "Iteration 7: 100%|██████████| 50/50 [00:05<00:00,  8.70it/s, episode=400, return=21.000]\n",
      "Iteration 8: 100%|██████████| 50/50 [00:05<00:00,  9.03it/s, episode=450, return=21.000]\n",
      "Iteration 9: 100%|██████████| 50/50 [00:05<00:00,  8.72it/s, episode=500, return=21.000]\n",
      "Iteration 0: 100%|██████████| 50/50 [00:07<00:00,  6.55it/s, episode=50, return=23.500]\n",
      "Iteration 1: 100%|██████████| 50/50 [00:06<00:00,  7.22it/s, episode=100, return=24.000]\n",
      "Iteration 2: 100%|██████████| 50/50 [00:05<00:00,  8.43it/s, episode=150, return=24.000]\n",
      "Iteration 3: 100%|██████████| 50/50 [00:06<00:00,  8.29it/s, episode=200, return=16.000]\n",
      "Iteration 4: 100%|██████████| 50/50 [00:07<00:00,  6.71it/s, episode=250, return=16.000]\n",
      "Iteration 5: 100%|██████████| 50/50 [00:05<00:00,  8.57it/s, episode=300, return=16.000]\n",
      "Iteration 6: 100%|██████████| 50/50 [00:06<00:00,  8.05it/s, episode=350, return=16.000]\n",
      "Iteration 7: 100%|██████████| 50/50 [00:06<00:00,  7.67it/s, episode=400, return=16.000]\n",
      "Iteration 8: 100%|██████████| 50/50 [00:06<00:00,  7.73it/s, episode=450, return=16.000]\n",
      "Iteration 9: 100%|██████████| 50/50 [00:05<00:00,  8.45it/s, episode=500, return=16.000]\n",
      "Iteration 0: 100%|██████████| 50/50 [00:07<00:00,  6.42it/s, episode=50, return=18.100]\n",
      "Iteration 1: 100%|██████████| 50/50 [00:06<00:00,  7.63it/s, episode=100, return=18.000]\n",
      "Iteration 2: 100%|██████████| 50/50 [00:05<00:00,  8.47it/s, episode=150, return=18.000]\n",
      "Iteration 3: 100%|██████████| 50/50 [00:05<00:00,  8.58it/s, episode=200, return=18.000]\n",
      "Iteration 4: 100%|██████████| 50/50 [00:05<00:00,  8.58it/s, episode=250, return=18.000]\n",
      "Iteration 5: 100%|██████████| 50/50 [00:05<00:00,  8.53it/s, episode=300, return=18.000]\n",
      "Iteration 6: 100%|██████████| 50/50 [00:05<00:00,  8.38it/s, episode=350, return=19.400]\n",
      "Iteration 7: 100%|██████████| 50/50 [00:05<00:00,  8.48it/s, episode=400, return=22.000]\n",
      "Iteration 8: 100%|██████████| 50/50 [00:05<00:00,  8.38it/s, episode=450, return=22.000]\n",
      "Iteration 9: 100%|██████████| 50/50 [00:05<00:00,  8.52it/s, episode=500, return=22.000]\n",
      "Iteration 0: 100%|██████████| 50/50 [00:07<00:00,  6.61it/s, episode=50, return=14.000]\n",
      "Iteration 1: 100%|██████████| 50/50 [00:07<00:00,  6.32it/s, episode=100, return=16.000]\n",
      "Iteration 2: 100%|██████████| 50/50 [00:07<00:00,  6.77it/s, episode=150, return=16.000]\n",
      "Iteration 3: 100%|██████████| 50/50 [00:06<00:00,  7.83it/s, episode=200, return=16.000]\n",
      "Iteration 4: 100%|██████████| 50/50 [00:06<00:00,  7.97it/s, episode=250, return=16.000]\n",
      "Iteration 5: 100%|██████████| 50/50 [00:06<00:00,  7.58it/s, episode=300, return=16.000]\n",
      "Iteration 6: 100%|██████████| 50/50 [00:06<00:00,  7.68it/s, episode=350, return=16.000]\n",
      "Iteration 7: 100%|██████████| 50/50 [00:06<00:00,  8.13it/s, episode=400, return=16.000]\n",
      "Iteration 8: 100%|██████████| 50/50 [00:06<00:00,  7.72it/s, episode=450, return=16.000]\n",
      "Iteration 9: 100%|██████████| 50/50 [00:06<00:00,  7.58it/s, episode=500, return=16.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 19.50±4.72, max: 20.50±4.63, mean: 20.10±4.66, median: 20.10±4.66\n"
     ]
    }
   ],
   "source": [
    "min_return = []\n",
    "max_return = []\n",
    "mean_return = []\n",
    "median_return = []\n",
    "for iter in range(10):\n",
    "    agent = train()\n",
    "    params[\"common\"][\"batch_size\"]=3000\n",
    "    mat_state = []\n",
    "    mat_return = []\n",
    "    env.initialize()\n",
    "    mat_state.append(env.state)\n",
    "    init_state = env.state\n",
    "    for h_iter in range(H-1):\n",
    "        batch_state = append_state(mat_state, H-1)\n",
    "        probs = agent.actor(batch_state.to(device))\n",
    "        actions_dist = torch.distributions.Categorical(probs)\n",
    "        actions = actions_dist.sample().cpu()\n",
    "        env.step(h_iter, actions)\n",
    "        mat_state.append(env.state)  # s+1\n",
    "\n",
    "    returns = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float()\n",
    "    min_return.append(returns.min())\n",
    "    max_return.append(returns.max())\n",
    "    mean_return.append(returns.mean())\n",
    "    median_return.append(returns.median())\n",
    "mean_min_return = np.mean(min_return)\n",
    "std_min_return = np.std(min_return)\n",
    "mean_max_return = np.mean(max_return)\n",
    "std_max_return = np.std(max_return)\n",
    "mean_mean_return = np.mean(mean_return)\n",
    "std_mean_return = np.std(mean_return)\n",
    "mean_median_return = np.mean(median_return)\n",
    "std_median_return = np.std(median_return)\n",
    "print(f\"min: {mean_min_return:.2f}±{std_min_return:.2f}, max: {mean_max_return:.2f}±{std_max_return:.2f}, mean: {mean_mean_return:.2f}±{std_mean_return:.2f}, median: {mean_median_return:.2f}±{std_median_return:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f17a348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_path_with_timesteps(states):\n",
    "    \"\"\"\n",
    "    从轨迹数据创建带时间步的路径\n",
    "    \"\"\"\n",
    "    # 将状态转换为带时间步的格式\n",
    "    path_with_time = [(t, state.item()) for t, state in enumerate(states)]\n",
    "    return path_with_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f7800ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 34), (1, 35), (2, 36), (3, 37), (4, 38), (5, 39), (6, 40), (7, 41), (8, 41), (9, 41), (10, 41), (11, 41), (12, 41), (13, 41), (14, 41), (15, 41), (16, 41), (17, 41), (18, 41), (19, 41), (20, 41), (21, 41), (22, 41), (23, 41), (24, 41), (25, 41), (26, 41), (27, 41), (28, 41), (29, 41), (30, 41), (31, 41), (32, 41), (33, 41), (34, 41), (35, 41), (36, 41), (37, 41), (38, 41), (39, 41)]\n",
      "tensor([16])\n",
      "x_ticks [-0.5001, -0.4999, 0.4999, 0.5001, 1.4999, 1.5001, 2.4999, 2.5001, 3.4999, 3.5001, 4.4999, 4.5001, 5.4999, 5.5001, 6.4999, 6.5001, 7.4999, 7.5001, 8.4999, 8.5001, 9.4999, 9.5001, 10.4999, 10.5001, 11.4999, 11.5001, 12.4999, 12.5001, 13.4999, 13.5001]\n",
      "y_ticks [-0.5001, -0.4999, 0.4999, 0.5001, 1.4999, 1.5001, 2.4999, 2.5001, 3.4999, 3.5001, 4.4999, 4.5001, 5.4999, 5.5001, 6.4999, 6.5001]\n",
      "x [6, 7, 8, 9, 10, 11, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13]\n",
      "y [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import importlib\n",
    "import visualization\n",
    "importlib.reload(visualization)\n",
    "from visualization import Visu\n",
    "params[\"common\"][\"batch_size\"]=1\n",
    "mat_state = []\n",
    "mat_return = []\n",
    "env.initialize()\n",
    "mat_state.append(env.state)\n",
    "init_state = env.state\n",
    "for h_iter in range(H-1):\n",
    "    if params[\"alg\"][\"type\"]==\"M\" or params[\"alg\"][\"type\"]==\"SRL\":\n",
    "        batch_state = mat_state[-1].reshape(-1, 1).float()\n",
    "        # append time index to the state\n",
    "        batch_state = torch.cat(\n",
    "            [batch_state, h_iter*torch.ones_like(batch_state)], 1)\n",
    "    else:\n",
    "        batch_state = append_state(mat_state, H-1)\n",
    "    probs = agent.actor(batch_state.to(device))\n",
    "    actions_dist = torch.distributions.Categorical(probs)\n",
    "    actions = actions_dist.sample()\n",
    "    env.step(h_iter, actions.cpu())\n",
    "    mat_state.append(env.state)  # s+1\n",
    "path = create_path_with_timesteps(mat_state)\n",
    "print(path)\n",
    "print(env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]))\n",
    "visu = Visu(env_params=params[\"env\"])\n",
    "visu.visu_path(path,env.Hori_ActionTransitionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b61da6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO agent's return: 16.0, min: 14.0, max: 18.0, mean: 16.0, var: 0.0016001600306481123\n"
     ]
    }
   ],
   "source": [
    "params[\"common\"][\"batch_size\"]=10000\n",
    "mat_state = []\n",
    "mat_return = []\n",
    "env.initialize()\n",
    "mat_state.append(env.state)\n",
    "init_state = env.state\n",
    "for h_iter in range(H-1):\n",
    "    batch_state = append_state(mat_state, H-1)\n",
    "    probs = agent.actor(batch_state.to(device))\n",
    "    actions_dist = torch.distributions.Categorical(probs)\n",
    "    actions = actions_dist.sample()\n",
    "    env.step(h_iter, actions.cpu())\n",
    "    mat_state.append(env.state)  # s+1\n",
    "min_return = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float().min()\n",
    "max_return = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float().max()\n",
    "mat_return = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float().mean()\n",
    "mean_return = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float().mean()\n",
    "var_return = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float().var()\n",
    "print(f\"PPO agent's return: {mat_return}, min: {min_return}, max: {max_return}, mean: {mean_return}, var: {var_return}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a1851fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "indices should be either on cpu or on the same device as the indexed tensor (cpu)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m     actions_dist \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mCategorical(probs)\n\u001b[0;32m     16\u001b[0m     actions \u001b[38;5;241m=\u001b[39m actions_dist\u001b[38;5;241m.\u001b[39msample()\n\u001b[1;32m---> 17\u001b[0m     env\u001b[38;5;241m.\u001b[39mstep(h_iter, actions)\n\u001b[0;32m     18\u001b[0m     mat_state\u001b[38;5;241m.\u001b[39mappend(env\u001b[38;5;241m.\u001b[39mstate)  \u001b[38;5;66;03m# s+1\u001b[39;00m\n\u001b[0;32m     20\u001b[0m returns \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mweighted_traj_return(mat_state, \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malg\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[1;32md:\\Users\\ZHY\\Documents\\GitHub\\non-additive-RL\\subrl\\utils\\environment.py:607\u001b[0m, in \u001b[0;36mGridWorld.step\u001b[1;34m(self, h, action)\u001b[0m\n\u001b[0;32m    605\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mHori_ActionTransitionMatrix[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, action]\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 607\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mHori_ActionTransitionMatrix[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, action]\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n",
      "\u001b[1;31mRuntimeError\u001b[0m: indices should be either on cpu or on the same device as the indexed tensor (cpu)"
     ]
    }
   ],
   "source": [
    "min_return = []\n",
    "max_return = []\n",
    "mean_return = []\n",
    "median_return = []\n",
    "for iter in range(10):\n",
    "    params[\"common\"][\"batch_size\"]=1000\n",
    "    mat_state = []\n",
    "    mat_return = []\n",
    "    env.initialize()\n",
    "    mat_state.append(env.state)\n",
    "    init_state = env.state\n",
    "    for h_iter in range(H-1):\n",
    "        batch_state = append_state(mat_state, H-1)\n",
    "        probs = agent.actor(batch_state.to(device))\n",
    "        actions_dist = torch.distributions.Categorical(probs)\n",
    "        actions = actions_dist.sample()\n",
    "        env.step(h_iter, actions)\n",
    "        mat_state.append(env.state)  # s+1\n",
    "\n",
    "    returns = env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]).float()\n",
    "    min_return.append(returns.min())\n",
    "    max_return.append(returns.max())\n",
    "    mean_return.append(returns.mean())\n",
    "    median_return.append(returns.median())\n",
    "mean_min_return = np.mean(min_return)\n",
    "std_min_return = np.std(min_return)\n",
    "mean_max_return = np.mean(max_return)\n",
    "std_max_return = np.std(max_return)\n",
    "mean_mean_return = np.mean(mean_return)\n",
    "std_mean_return = np.std(mean_return)\n",
    "mean_median_return = np.mean(median_return)\n",
    "std_median_return = np.std(median_return)\n",
    "print(f\"min: {mean_min_return:.2f}±{std_min_return:.2f}, max: {mean_max_return:.2f}±{std_max_return:.2f}, mean: {mean_mean_return:.2f}±{std_mean_return:.2f}, median: {mean_median_return:.2f}±{std_median_return:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3661c44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
