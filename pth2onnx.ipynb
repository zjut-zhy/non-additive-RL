{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ada29cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始转换CQL模型...\n",
      "网络参数: state_dim=39, hidden_dim=128, action_dim=5\n",
      "正在转换Actor网络...\n",
      "正在转换Critic1网络...\n",
      "正在转换Critic2网络...\n",
      "转换完成！ONNX文件保存在: ./onnx_models\n",
      "✓ cql_actor.onnx 验证成功，输出形状: (1, 5)\n",
      "✓ cql_critic1.onnx 验证成功，输出形状: (1, 5)\n",
      "✓ cql_critic2.onnx 验证成功，输出形状: (1, 5)\n",
      "正在转换推理模型...\n",
      "推理模型转换完成！\n",
      "\n",
      "所有转换完成！\n",
      "生成的文件:\n",
      "- cql_actor.onnx: Actor网络\n",
      "- cql_critic1.onnx: Critic1网络\n",
      "- cql_critic2.onnx: Critic2网络\n",
      "- cql_inference.onnx: 完整推理模型\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "# 首先需要重新定义网络结构（与您原始代码中的结构相同）\n",
    "class PolicyNet(torch.nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim):\n",
    "        super(PolicyNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, action_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        return torch.nn.functional.softmax(self.fc2(x), dim=1)\n",
    "\n",
    "class QValueNet(torch.nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim):\n",
    "        super(QValueNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, action_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "def convert_cql_model_to_onnx(model_path, output_dir=\"./onnx_models\"):\n",
    "    \"\"\"\n",
    "    将CQL模型转换为ONNX格式\n",
    "    \n",
    "    Args:\n",
    "        model_path: CQL模型文件路径\n",
    "        output_dir: ONNX文件输出目录\n",
    "    \"\"\"\n",
    "    # 创建输出目录\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 加载保存的模型检查点\n",
    "    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "    \n",
    "    # 从超参数中获取网络结构信息\n",
    "    hyperparams = checkpoint.get('hyperparameters', {})\n",
    "    \n",
    "    # 设置网络参数（根据您的代码推断）\n",
    "    state_dim = 39  # H-1，根据您的代码\n",
    "    hidden_dim = 128\n",
    "    action_dim = hyperparams.get('action_dim', 5)\n",
    "    \n",
    "    print(f\"网络参数: state_dim={state_dim}, hidden_dim={hidden_dim}, action_dim={action_dim}\")\n",
    "    \n",
    "    # 创建网络实例\n",
    "    actor = PolicyNet(state_dim, hidden_dim, action_dim)\n",
    "    critic_1 = QValueNet(state_dim, hidden_dim, action_dim)\n",
    "    critic_2 = QValueNet(state_dim, hidden_dim, action_dim)\n",
    "    \n",
    "    # 加载权重\n",
    "    actor.load_state_dict(checkpoint['actor_state_dict'])\n",
    "    critic_1.load_state_dict(checkpoint['critic_1_state_dict'])\n",
    "    critic_2.load_state_dict(checkpoint['critic_2_state_dict'])\n",
    "    \n",
    "    # 设置为评估模式\n",
    "    actor.eval()\n",
    "    critic_1.eval()\n",
    "    critic_2.eval()\n",
    "    \n",
    "    # 创建示例输入\n",
    "    dummy_input = torch.randn(1, state_dim)\n",
    "    \n",
    "    # 转换Actor网络\n",
    "    print(\"正在转换Actor网络...\")\n",
    "    torch.onnx.export(\n",
    "        actor,\n",
    "        dummy_input,\n",
    "        os.path.join(output_dir, \"cql_actor.onnx\"),\n",
    "        export_params=True,\n",
    "        opset_version=11,\n",
    "        do_constant_folding=True,\n",
    "        input_names=['state'],\n",
    "        output_names=['action_probs'],\n",
    "        dynamic_axes={\n",
    "            'state': {0: 'batch_size'},\n",
    "            'action_probs': {0: 'batch_size'}\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # 转换Critic1网络\n",
    "    print(\"正在转换Critic1网络...\")\n",
    "    torch.onnx.export(\n",
    "        critic_1,\n",
    "        dummy_input,\n",
    "        os.path.join(output_dir, \"cql_critic1.onnx\"),\n",
    "        export_params=True,\n",
    "        opset_version=11,\n",
    "        do_constant_folding=True,\n",
    "        input_names=['state'],\n",
    "        output_names=['q_values'],\n",
    "        dynamic_axes={\n",
    "            'state': {0: 'batch_size'},\n",
    "            'q_values': {0: 'batch_size'}\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # 转换Critic2网络\n",
    "    print(\"正在转换Critic2网络...\")\n",
    "    torch.onnx.export(\n",
    "        critic_2,\n",
    "        dummy_input,\n",
    "        os.path.join(output_dir, \"cql_critic2.onnx\"),\n",
    "        export_params=True,\n",
    "        opset_version=11,\n",
    "        do_constant_folding=True,\n",
    "        input_names=['state'],\n",
    "        output_names=['q_values'],\n",
    "        dynamic_axes={\n",
    "            'state': {0: 'batch_size'},\n",
    "            'q_values': {0: 'batch_size'}\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(f\"转换完成！ONNX文件保存在: {output_dir}\")\n",
    "    \n",
    "    # 验证ONNX模型\n",
    "    verify_onnx_models(output_dir, dummy_input)\n",
    "\n",
    "def verify_onnx_models(onnx_dir, test_input):\n",
    "    \"\"\"\n",
    "    验证ONNX模型是否正确转换\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import onnx\n",
    "        import onnxruntime as ort\n",
    "        \n",
    "        model_files = ['cql_actor.onnx', 'cql_critic1.onnx', 'cql_critic2.onnx']\n",
    "        \n",
    "        for model_file in model_files:\n",
    "            model_path = os.path.join(onnx_dir, model_file)\n",
    "            \n",
    "            # 验证ONNX模型格式\n",
    "            onnx_model = onnx.load(model_path)\n",
    "            onnx.checker.check_model(onnx_model)\n",
    "            \n",
    "            # 测试推理\n",
    "            ort_session = ort.InferenceSession(model_path)\n",
    "            input_name = ort_session.get_inputs()[0].name\n",
    "            output = ort_session.run(None, {input_name: test_input.numpy()})\n",
    "            \n",
    "            print(f\"✓ {model_file} 验证成功，输出形状: {output[0].shape}\")\n",
    "            \n",
    "    except ImportError:\n",
    "        print(\"警告: 没有安装onnx或onnxruntime，跳过验证步骤\")\n",
    "        print(\"可以运行: pip install onnx onnxruntime 来安装验证工具\")\n",
    "\n",
    "# 创建一个简化的推理类，也可以转换为ONNX\n",
    "class CQLActorInference(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    用于推理的简化Actor模型\n",
    "    \"\"\"\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim):\n",
    "        super(CQLActorInference, self).__init__()\n",
    "        self.actor = PolicyNet(state_dim, hidden_dim, action_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        probs = self.actor(x)\n",
    "        # 返回概率分布和最可能的动作\n",
    "        action = torch.argmax(probs, dim=1)\n",
    "        return probs, action\n",
    "\n",
    "def convert_cql_inference_model(model_path, output_dir=\"./onnx_models\"):\n",
    "    \"\"\"\n",
    "    转换用于推理的完整CQL模型\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "    hyperparams = checkpoint.get('hyperparameters', {})\n",
    "    \n",
    "    state_dim = 39\n",
    "    hidden_dim = 128\n",
    "    action_dim = hyperparams.get('action_dim', 5)\n",
    "    \n",
    "    # 创建推理模型\n",
    "    inference_model = CQLActorInference(state_dim, hidden_dim, action_dim)\n",
    "    inference_model.actor.load_state_dict(checkpoint['actor_state_dict'])\n",
    "    inference_model.eval()\n",
    "    \n",
    "    dummy_input = torch.randn(1, state_dim)\n",
    "    \n",
    "    print(\"正在转换推理模型...\")\n",
    "    torch.onnx.export(\n",
    "        inference_model,\n",
    "        dummy_input,\n",
    "        os.path.join(output_dir, \"cql_inference.onnx\"),\n",
    "        export_params=True,\n",
    "        opset_version=11,\n",
    "        do_constant_folding=True,\n",
    "        input_names=['state'],\n",
    "        output_names=['action_probs', 'predicted_action'],\n",
    "        dynamic_axes={\n",
    "            'state': {0: 'batch_size'},\n",
    "            'action_probs': {0: 'batch_size'},\n",
    "            'predicted_action': {0: 'batch_size'}\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(\"推理模型转换完成！\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 转换您的模型\n",
    "    model_path = \"./saved_models/cql_model_64.pth\"\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        print(\"开始转换CQL模型...\")\n",
    "        \n",
    "        # 转换各个网络组件\n",
    "        convert_cql_model_to_onnx(model_path)\n",
    "        \n",
    "        # 转换推理模型\n",
    "        convert_cql_inference_model(model_path)\n",
    "        \n",
    "        print(\"\\n所有转换完成！\")\n",
    "        print(\"生成的文件:\")\n",
    "        print(\"- cql_actor.onnx: Actor网络\")\n",
    "        print(\"- cql_critic1.onnx: Critic1网络\")\n",
    "        print(\"- cql_critic2.onnx: Critic2网络\")\n",
    "        print(\"- cql_inference.onnx: 完整推理模型\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"错误: 模型文件不存在 {model_path}\")\n",
    "        print(\"请确保模型文件路径正确\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5d72e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
