{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf30926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import matplotlib.pyplot as plt\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3628d00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import errno\n",
    "import os\n",
    "import random\n",
    "from importlib.metadata import requires\n",
    "from timeit import timeit\n",
    "import dill as pickle\n",
    "import numpy as np\n",
    "import scipy\n",
    "import torch\n",
    "import wandb\n",
    "import yaml\n",
    "from sympy import Matrix, MatrixSymbol, derive_by_array, symarray\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "from environment import GridWorld\n",
    "from subrl.utils.network import append_state\n",
    "from subrl.utils.network import policy as agent_net\n",
    "from subrl.utils.visualization import Visu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cbbd709",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    ''' 经验回放池 '''\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = collections.deque(maxlen=capacity)  # 队列,先进先出\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):  # 将数据加入buffer\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def sample(self, batch_size):  # 从buffer中采样数据,数量为batch_size\n",
    "        transitions = random.sample(self.buffer, batch_size)\n",
    "        state, action, reward, next_state, done = zip(*transitions)\n",
    "        return np.array(state), action, reward, np.array(next_state), done\n",
    "\n",
    "    def size(self):  # 目前buffer中数据的数量\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "755e8fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNet(torch.nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim):\n",
    "        super(PolicyNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, action_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return F.softmax(self.fc2(x), dim=1)\n",
    "\n",
    "\n",
    "class QValueNet(torch.nn.Module):\n",
    "    ''' 只有一层隐藏层的Q网络 '''\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim):\n",
    "        super(QValueNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, action_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "class SAC:\n",
    "    ''' 处理离散动作的SAC算法 '''\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim, actor_lr, critic_lr,\n",
    "                 alpha_lr, target_entropy, tau, gamma, device):\n",
    "        # 策略网络\n",
    "        self.actor = PolicyNet(state_dim, hidden_dim, action_dim).to(device)\n",
    "        # 第一个Q网络\n",
    "        self.critic_1 = QValueNet(state_dim, hidden_dim, action_dim).to(device)\n",
    "        # 第二个Q网络\n",
    "        self.critic_2 = QValueNet(state_dim, hidden_dim, action_dim).to(device)\n",
    "        self.target_critic_1 = QValueNet(state_dim, hidden_dim,\n",
    "                                         action_dim).to(device)  # 第一个目标Q网络\n",
    "        self.target_critic_2 = QValueNet(state_dim, hidden_dim,\n",
    "                                         action_dim).to(device)  # 第二个目标Q网络\n",
    "        # 令目标Q网络的初始参数和Q网络一样\n",
    "        self.target_critic_1.load_state_dict(self.critic_1.state_dict())\n",
    "        self.target_critic_2.load_state_dict(self.critic_2.state_dict())\n",
    "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(),\n",
    "                                                lr=actor_lr)\n",
    "        self.critic_1_optimizer = torch.optim.Adam(self.critic_1.parameters(),\n",
    "                                                   lr=critic_lr)\n",
    "        self.critic_2_optimizer = torch.optim.Adam(self.critic_2.parameters(),\n",
    "                                                   lr=critic_lr)\n",
    "        # 使用alpha的log值,可以使训练结果比较稳定\n",
    "        self.log_alpha = torch.tensor(np.log(0.01), dtype=torch.float)\n",
    "        self.log_alpha.requires_grad = True  # 可以对alpha求梯度\n",
    "        self.log_alpha_optimizer = torch.optim.Adam([self.log_alpha],\n",
    "                                                    lr=alpha_lr)\n",
    "        self.target_entropy = target_entropy  # 目标熵的大小\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.device = device\n",
    "\n",
    "    def take_action(self, state):\n",
    "        state = torch.tensor([state], dtype=torch.float).to(self.device)\n",
    "        probs = self.actor(state)\n",
    "        action_dist = torch.distributions.Categorical(probs)\n",
    "        action = action_dist.sample()\n",
    "        return action.item()\n",
    "\n",
    "    # 计算目标Q值,直接用策略网络的输出概率进行期望计算\n",
    "    def calc_target(self, rewards, next_states, dones):\n",
    "        next_probs = self.actor(next_states)\n",
    "        next_log_probs = torch.log(next_probs + 1e-8)\n",
    "        entropy = -torch.sum(next_probs * next_log_probs, dim=1, keepdim=True)\n",
    "        q1_value = self.target_critic_1(next_states)\n",
    "        q2_value = self.target_critic_2(next_states)\n",
    "        min_qvalue = torch.sum(next_probs * torch.min(q1_value, q2_value),\n",
    "                               dim=1,\n",
    "                               keepdim=True)\n",
    "        next_value = min_qvalue + self.log_alpha.exp() * entropy\n",
    "        td_target = rewards + self.gamma * next_value * (1 - dones)\n",
    "        return td_target\n",
    "\n",
    "    def soft_update(self, net, target_net):\n",
    "        for param_target, param in zip(target_net.parameters(),\n",
    "                                       net.parameters()):\n",
    "            param_target.data.copy_(param_target.data * (1.0 - self.tau) +\n",
    "                                    param.data * self.tau)\n",
    "\n",
    "    def update(self, transition_dict):\n",
    "        states = torch.tensor(transition_dict['states'],\n",
    "                              dtype=torch.float).to(self.device)\n",
    "        actions = torch.tensor(transition_dict['actions']).view(-1, 1).to(\n",
    "            self.device)  # 动作不再是float类型\n",
    "        rewards = torch.tensor(transition_dict['rewards'],\n",
    "                               dtype=torch.float).view(-1, 1).to(self.device)\n",
    "        next_states = torch.tensor(transition_dict['next_states'],\n",
    "                                   dtype=torch.float).to(self.device)\n",
    "        dones = torch.tensor(transition_dict['dones'],\n",
    "                             dtype=torch.float).view(-1, 1).to(self.device)\n",
    "\n",
    "        # 更新两个Q网络\n",
    "        td_target = self.calc_target(rewards, next_states, dones)\n",
    "        critic_1_q_values = self.critic_1(states).gather(1, actions)\n",
    "        critic_1_loss = torch.mean(\n",
    "            F.mse_loss(critic_1_q_values, td_target.detach()))\n",
    "        critic_2_q_values = self.critic_2(states).gather(1, actions)\n",
    "        critic_2_loss = torch.mean(\n",
    "            F.mse_loss(critic_2_q_values, td_target.detach()))\n",
    "        self.critic_1_optimizer.zero_grad()\n",
    "        critic_1_loss.backward()\n",
    "        self.critic_1_optimizer.step()\n",
    "        self.critic_2_optimizer.zero_grad()\n",
    "        critic_2_loss.backward()\n",
    "        self.critic_2_optimizer.step()\n",
    "\n",
    "        # 更新策略网络\n",
    "        probs = self.actor(states)\n",
    "        log_probs = torch.log(probs + 1e-8)\n",
    "        # 直接根据概率计算熵\n",
    "        entropy = -torch.sum(probs * log_probs, dim=1, keepdim=True)  #\n",
    "        q1_value = self.critic_1(states)\n",
    "        q2_value = self.critic_2(states)\n",
    "        min_qvalue = torch.sum(probs * torch.min(q1_value, q2_value),\n",
    "                               dim=1,\n",
    "                               keepdim=True)  # 直接根据概率计算期望\n",
    "        actor_loss = torch.mean(-self.log_alpha.exp() * entropy - min_qvalue)\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        # 更新alpha值\n",
    "        alpha_loss = torch.mean(\n",
    "            (entropy - self.target_entropy).detach() * self.log_alpha.exp())\n",
    "        self.log_alpha_optimizer.zero_grad()\n",
    "        alpha_loss.backward()\n",
    "        self.log_alpha_optimizer.step()\n",
    "\n",
    "        self.soft_update(self.critic_1, self.target_critic_1)\n",
    "        self.soft_update(self.critic_2, self.target_critic_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce7c735d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'env': {'start': 1, 'step_size': 0.1, 'shape': {'x': 10, 'y': 18}, 'horizon': 80, 'node_weight': 'constant', 'disc_size': 'small', 'n_players': 3, 'Cx_lengthscale': 2, 'Cx_noise': 0.001, 'Fx_lengthscale': 1, 'Fx_noise': 0.001, 'Cx_beta': 1.5, 'Fx_beta': 1.5, 'generate': False, 'env_file_name': 'env_data.pkl', 'cov_module': 'Matern', 'stochasticity': 0.0, 'domains': 'two_room_2', 'num': 1, 'initial': 80}, 'alg': {'gamma': 1, 'type': 'NM', 'ent_coef': 0.0, 'epochs': 140, 'lr': 0.02}, 'common': {'a': 1, 'subgrad': 'greedy', 'grad': 'pytorch', 'algo': 'both', 'init': 'deterministic', 'batch_size': 3000}, 'visu': {'wb': 'disabled', 'a': 1}}\n",
      "x_ticks [-0.5001, -0.4999, 0.4999, 0.5001, 1.4999, 1.5001, 2.4999, 2.5001, 3.4999, 3.5001, 4.4999, 4.5001, 5.4999, 5.5001, 6.4999, 6.5001, 7.4999, 7.5001, 8.4999, 8.5001, 9.4999, 9.5001, 10.4999, 10.5001, 11.4999, 11.5001, 12.4999, 12.5001, 13.4999, 13.5001, 14.4999, 14.5001, 15.4999, 15.5001, 16.4999, 16.5001, 17.4999, 17.5001]\n",
      "y_ticks [-0.5001, -0.4999, 0.4999, 0.5001, 1.4999, 1.5001, 2.4999, 2.5001, 3.4999, 3.5001, 4.4999, 4.5001, 5.4999, 5.5001, 6.4999, 6.5001, 7.4999, 7.5001, 8.4999, 8.5001, 9.4999, 9.5001]\n"
     ]
    }
   ],
   "source": [
    "workspace = \"subrl\"\n",
    "\n",
    "params = {\n",
    "    \"env\": {\n",
    "        \"start\": 1,\n",
    "        \"step_size\": 0.1,\n",
    "        \"shape\": {\"x\": 10, \"y\": 18},\n",
    "        \"horizon\": 80,\n",
    "        \"node_weight\": \"constant\",\n",
    "        \"disc_size\": \"small\",\n",
    "        \"n_players\": 3,\n",
    "        \"Cx_lengthscale\": 2,\n",
    "        \"Cx_noise\": 0.001,\n",
    "        \"Fx_lengthscale\": 1,\n",
    "        \"Fx_noise\": 0.001,\n",
    "        \"Cx_beta\": 1.5,\n",
    "        \"Fx_beta\": 1.5,\n",
    "        \"generate\": False,\n",
    "        \"env_file_name\": 'env_data.pkl',\n",
    "        \"cov_module\": 'Matern',\n",
    "        \"stochasticity\": 0.0,\n",
    "        \"domains\": \"two_room_2\",\n",
    "        \"num\": 1,  # 替代原来的args.env\n",
    "        \"initial\": 80\n",
    "    },\n",
    "    \"alg\": {\n",
    "        \"gamma\": 1,\n",
    "        \"type\": \"NM\",\n",
    "        \"ent_coef\": 0.0,\n",
    "        \"epochs\": 140,\n",
    "        \"lr\": 0.02\n",
    "    },\n",
    "    \"common\": {\n",
    "        \"a\": 1,\n",
    "        \"subgrad\": \"greedy\",\n",
    "        \"grad\": \"pytorch\",\n",
    "        \"algo\": \"both\",\n",
    "        \"init\": \"deterministic\",\n",
    "        \"batch_size\": 3000\n",
    "    },\n",
    "    \"visu\": {\n",
    "        \"wb\": \"disabled\",\n",
    "        \"a\": 1\n",
    "    }\n",
    "}\n",
    "\n",
    "print(params)\n",
    "\n",
    "# 2) Set the path and copy params from file\n",
    "env_load_path = workspace + \\\n",
    "    \"/environments/\" + params[\"env\"][\"node_weight\"]+ \"/env_\" + \\\n",
    "    str(params[\"env\"][\"num\"])\n",
    "\n",
    "\n",
    "\n",
    "epochs = params[\"alg\"][\"epochs\"]\n",
    "\n",
    "H = params[\"env\"][\"horizon\"]\n",
    "MAX_Ret = 2*(H+1)\n",
    "if params[\"env\"][\"disc_size\"] == \"large\":\n",
    "    MAX_Ret = 3*(H+2)\n",
    "\n",
    "# 3) Setup the environement\n",
    "env = GridWorld(\n",
    "    env_params=params[\"env\"], common_params=params[\"common\"], visu_params=params[\"visu\"], env_file_path=env_load_path)\n",
    "node_size = params[\"env\"][\"shape\"]['x']*params[\"env\"][\"shape\"]['y']\n",
    "# TransitionMatrix = torch.zeros(node_size, node_size)\n",
    "\n",
    "if params[\"env\"][\"node_weight\"] == \"entropy\" or params[\"env\"][\"node_weight\"] == \"steiner_covering\" or params[\"env\"][\"node_weight\"] == \"GP\": \n",
    "    a_file = open(env_load_path +\".pkl\", \"rb\")\n",
    "    data = pickle.load(a_file)\n",
    "    a_file.close()\n",
    "\n",
    "if params[\"env\"][\"node_weight\"] == \"entropy\":\n",
    "    env.cov = data\n",
    "if params[\"env\"][\"node_weight\"] == \"steiner_covering\":\n",
    "    env.items_loc = data\n",
    "if params[\"env\"][\"node_weight\"] == \"GP\":\n",
    "    env.weight = data\n",
    "\n",
    "visu = Visu(env_params=params[\"env\"])\n",
    "\n",
    "env.get_horizon_transition_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb72bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dim = H-1\n",
    "action_dim = 5\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "actor_lr = 3e-4\n",
    "critic_lr = 3e-3\n",
    "alpha_lr = 3e-4\n",
    "num_episodes = 1000\n",
    "hidden_dim = 128\n",
    "gamma = 0.99\n",
    "tau = 0.005  # 软更新参数\n",
    "buffer_size = 100000\n",
    "minimal_size = 1000\n",
    "batch_size = 640\n",
    "target_entropy = -1\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\n",
    "    \"cpu\")\n",
    "replay_buffer = ReplayBuffer(buffer_size)\n",
    "agent = SAC(state_dim, hidden_dim, action_dim, actor_lr, critic_lr, alpha_lr,\n",
    "            target_entropy, tau, gamma, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4654cbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 0: 100%|██████████| 100/100 [01:03<00:00,  1.59it/s, episode=100, return=36.000]\n",
      "Iteration 1: 100%|██████████| 100/100 [01:25<00:00,  1.17it/s, episode=200, return=36.000]\n",
      "Iteration 2: 100%|██████████| 100/100 [01:34<00:00,  1.06it/s, episode=300, return=36.000]\n",
      "Iteration 3:  76%|███████▌  | 76/100 [01:06<00:26,  1.12s/it, episode=370, return=36.000]"
     ]
    }
   ],
   "source": [
    "params[\"common\"][\"batch_size\"]=100      #采样的batch大小\n",
    "return_list = []\n",
    "for i in range(10):\n",
    "    with tqdm(total=int(num_episodes / 10), desc='Iteration %d' % i) as pbar:\n",
    "        for i_episode in range(int(num_episodes / 10)):\n",
    "            mat_state = []\n",
    "            mat_return = []\n",
    "            env.initialize(params[\"env\"][\"initial\"])\n",
    "            mat_state.append(env.state)\n",
    "            init_state = env.state\n",
    "            for h_iter in range(H-1):\n",
    "                batch_state = append_state(mat_state, H-1)\n",
    "\n",
    "                probs = agent.actor(batch_state.to(device))\n",
    "                actions_dist = torch.distributions.Categorical(probs)\n",
    "                actions = actions_dist.sample()\n",
    "\n",
    "                env.step(h_iter, actions.cpu())\n",
    "\n",
    "                mat_state.append(env.state)  # s+1\n",
    "                mat_return.append(env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"]))\n",
    "                if h_iter == 0:\n",
    "                    reward = mat_return[-1]\n",
    "                else:\n",
    "                    reward = mat_return[-1]-mat_return[-2]\n",
    "\n",
    "                if h_iter == H-2:\n",
    "                    next_state = batch_state\n",
    "                    done = 1\n",
    "                else:\n",
    "                    next_state = append_state(mat_state, H-1)\n",
    "                    done = 0\n",
    "\n",
    "                for j in range(params[\"common\"][\"batch_size\"]):\n",
    "                    replay_buffer.add(batch_state[j],actions[j],reward[j],next_state[j],done)\n",
    "\n",
    "                # 当buffer数据的数量超过一定值后,才进行Q网络训练\n",
    "                if replay_buffer.size() > minimal_size:\n",
    "                    b_s, b_a, b_r, b_ns, b_d = replay_buffer.sample(batch_size)\n",
    "                    transition_dict = {\n",
    "                        'states': b_s,\n",
    "                        'actions': b_a,\n",
    "                        'next_states': b_ns,\n",
    "                        'rewards': b_r,\n",
    "                        'dones': b_d\n",
    "                    }\n",
    "                    agent.update(transition_dict)\n",
    "\n",
    "            return_list.append(mat_return[-1].float().mean())\n",
    "\n",
    "            if (i_episode + 1) % 10 == 0:\n",
    "                pbar.set_postfix({\n",
    "                    'episode':\n",
    "                    '%d' % (num_episodes / 10 * i + i_episode + 1),\n",
    "                    'return':\n",
    "                    '%.3f' % np.mean(return_list[-10:])\n",
    "                })\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfe030ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[\"common\"][\"batch_size\"]=1\n",
    "mat_state = []\n",
    "mat_return = []\n",
    "env.initialize()\n",
    "mat_state.append(env.state)\n",
    "init_state = env.state\n",
    "for h_iter in range(H-1):\n",
    "    if params[\"alg\"][\"type\"]==\"M\" or params[\"alg\"][\"type\"]==\"SRL\":\n",
    "        batch_state = mat_state[-1].reshape(-1, 1).float()\n",
    "        # append time index to the state\n",
    "        batch_state = torch.cat(\n",
    "            [batch_state, h_iter*torch.ones_like(batch_state)], 1)\n",
    "    else:\n",
    "        batch_state = append_state(mat_state, H-1)\n",
    "    probs = agent.actor(batch_state.to(device))\n",
    "    actions_dist = torch.distributions.Categorical(probs)\n",
    "    actions = actions_dist.sample()\n",
    "    env.step(h_iter, actions)\n",
    "    mat_state.append(env.state)  # s+1\n",
    "env.weighted_traj_return(mat_state, type = params[\"alg\"][\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f19247be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 34), (1, 33), (2, 32), (3, 31), (4, 30), (5, 29), (6, 28), (7, 42), (8, 56), (9, 70), (10, 84), (11, 84), (12, 84), (13, 84), (14, 84), (15, 84), (16, 84), (17, 84), (18, 84), (19, 84), (20, 84), (21, 84), (22, 84), (23, 84), (24, 84), (25, 84), (26, 84), (27, 84), (28, 84), (29, 84), (30, 84), (31, 84), (32, 84), (33, 84), (34, 84), (35, 84), (36, 84), (37, 84), (38, 84), (39, 84)]\n"
     ]
    }
   ],
   "source": [
    "def create_path_with_timesteps(states):\n",
    "    \"\"\"\n",
    "    从轨迹数据创建带时间步的路径\n",
    "    \"\"\"\n",
    "    # 将状态转换为带时间步的格式\n",
    "    path_with_time = [(t, state.item()) for t, state in enumerate(states)]\n",
    "    return path_with_time\n",
    "path = create_path_with_timesteps(mat_state)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41e19404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_ticks [-0.5001, -0.4999, 0.4999, 0.5001, 1.4999, 1.5001, 2.4999, 2.5001, 3.4999, 3.5001, 4.4999, 4.5001, 5.4999, 5.5001, 6.4999, 6.5001, 7.4999, 7.5001, 8.4999, 8.5001, 9.4999, 9.5001, 10.4999, 10.5001, 11.4999, 11.5001, 12.4999, 12.5001, 13.4999, 13.5001]\n",
      "y_ticks [-0.5001, -0.4999, 0.4999, 0.5001, 1.4999, 1.5001, 2.4999, 2.5001, 3.4999, 3.5001, 4.4999, 4.5001, 5.4999, 5.5001, 6.4999, 6.5001]\n",
      "x [6, 5, 4, 3, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "y [2, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import importlib\n",
    "import visualization\n",
    "importlib.reload(visualization)\n",
    "from visualization import Visu\n",
    "visu = Visu(env_params=params[\"env\"])\n",
    "visu.visu_path(path,env.Hori_ActionTransitionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85e7f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562499c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
